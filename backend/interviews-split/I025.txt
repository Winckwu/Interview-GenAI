受访人25:
2025-09-09 20:37:26 CST|1h 10min 58s

Keywords:
交互、文献、框架、语料、模态、生成式、语境、计算机、智能、语言模型、人机交互、自然语言处理、生成式模型、代码输出、语境语言、语言表述、记忆系统、评估学生

Transcript:
Speaker 1 00:00 
好，行，那我们正式开始就是这边是商学院的一个项目，是关于基于交互记忆系统来优化人机团队表现的一个研究，主要是想了解一下，就是甚至是 AI 这个高频使用者，就是在你们在学习或者工作的过程中是如何跟 AI 进行协作的，也就是想了解你们每个任务中的一个具体的一个协作方式，或者是一个的思考方式。您对这个有什么问题吗？没有问题，我们就继续。

Speaker 2 00:37 
没有问题，可以继续。

Speaker 1 00:38 
好，行，那您能简单的描述一下你目前的职业或者学习的领域吗？

Speaker 2 00:47 
我现在是，现在的职业是算是做AI，然后和 AI 加教育这两个领域，然后目前的职业是算是科研从业者这样，然后，诶，第二个问题是什么？

Speaker 1 01:13 
对，也没关系，就是在对于这个领域的话，你通常会处理哪些类型的任务？

Speaker 2 01:22 
我最经常做的一个事就是在一般使用的过程中，或者使用那个已经有了那个前端 1 GUI 的那种大模型的，就比如说 ChatGPT cloud 这种主要是辅助，就是做一些工作，文字书面的工作，然后也包括代码的一些工作。然后还有的话就是用那个API，然后用 API 去搭建那个 AI 的多智能体框架，或者是智能体框架。然后常用的话一个是直接，我基本上是如果说是做 AI 相关的，基本上全都是用那个代码，直接那个去叫这个API，就直接 call API。然后有一些就是特殊的，比如说那个 AI for education，就是 nie 那边的项目的话，他们会要求就只能用 diffy 的那个框架，这个框架相当于它是专门为这个智能体设计的一种框架，当然它有局限，它又有好用的地方，这个就是各有利弊吧。对，然后所以就是纯自己搭的话也可以，然后也用框架的话也会用。对，嗯。

Speaker 1 02:45 
OK。那大概是从什么时候开始使用 AI 这些工具的？

Speaker 2 02:51 
嗯，是从 23 年开始，就准确来说应该是 22 年 11 月 10 就是十月 11 月这样。诶，因为那个时候是那个 GPT 刚出来，就是它刚商业化。

Speaker 1 03:03 
那是读硕吗？他还是。

Speaker 2 03:05 
在读硕士的时候，都不都是硕士，硕士。对对对。

Speaker 1 03:11 
那时候的话就会也是处理，也对，那时候也不是教育学的话，那会处理什么类型任务？那时候任务是不太一样。

Speaker 2 03:21 
那个时候主要还算是，我觉得那个时候其实开始的话就是 2 三年，应该说是 22 年年底的那段时间，其实主要是用那个他有这个用户交互页面的这个PPT。嗯嗯，也没有，这个啥也没有，就是能可以听到吗。

Speaker 1 03:44 
呃？有点小声，突然有点小声哦。

Speaker 2 03:53 
喂喂，可以听到吗。

Speaker 1 03:56 
现在可以。

Speaker 2 03:58 
ok，那我就这样，我比较好，OK，那个就是开始的时候其实就是对 API 是没有概念的，那个时候也不会说是，就是他不会说是直接给这种开放后端，他只会开放一个前端，然后让你从前端去使用，可以听到。

Speaker 1 04:18 
吗？可以，没问题。

Speaker 2 04:21 
OK，然后那然后到了 23 年开始的话，就是他开始慢慢的就是开放，就这些 commercial company 他们就会慢慢去 CO- 开放那个API，就相当于他在后端开了一个接口。然后你可以只要有这个觅食，然后就可以去调用它的API，然后直接用它的模型，然后按照这个字数或者说 TOKEN 数算钱。然后后面是这样的，然后但是前面就开发的话，肯定还是需要去用API，就是开二三年的时候是没有那个框架的，就是开始是没有框架。这样的后面有了，比如说那个 long chain，或者说是再到后面就是像 diffy 这种，它有这个用户直接能看到的这个 visualize 的界面，但是开始的那些框架都是代码为主的，就是它全都是代码帮你已经搭好的一些框架，它相当于给你节省时间，当然也不是说的所有你都可以依靠框架，但是这个就是后面的事情，对， API 更多是后面的事情，就是做开发。

Speaker 1 05:28 
那这个因为我现在好奇，就是因为学科的变化，就是会不会任务也会出现变化？就是跟 AI 之间的一些任务交互。

Speaker 2 05:39 
科研上面有一个非常，就是这个是科研上面的，还是说是学科学习，或者说是。

Speaker 1 05:45 
都行，或者。

Speaker 2 05:46 
某一个学科。

Speaker 1 05:48 
都行。对。

Speaker 2 05:50 
ok，就是从那个，就是我接触的比较多的是那个自然语言处理，就是这个领域，然后其他领域因为我接触的不是特别多，就开始的话自然语言处理就是当时 22 年的时候还在用一些大模型，但是没有说是像 GPT 这么大的模型，就是当时是在用T5，或者说是就是有一些Bert，然后各种个 Bert 模型它用得比较多。然后到了 22 年开始这不是有了，就是生成式大模型，而且是这种商业化的生成式大模型。嗯嗯，从那个阶段开始，就是大家才反应上，也不是反应，就是大家才发现，就是之前的这些比较小的模型的一些功能，可以被这些更大的模型替代，然后这些大的模型里面，就是这些超大模型也有开源的，也有闭源的，开源的也就是那个 LLAMA 或者千问，就是千问是之后的 LLAMA 开始比较能够是有开源、有闭源，但是整体来上，整体上来讲就这种模型的话，这种生成式模型它基本上可以满足之前使用，比如说使用 Bert 呀，或者使用 T5 呀。

Speaker 2 07:08 
就是这种模型的所有需求，不管是分类任务还是说是，就尤其是生成式任务，然后因为生成对于语言来说是一个非常重要的任务，就是语言它可以不说是，就是分类它可能是一个小任务，但生成其实才是语言的这个本质啊。然后就大家就开始就是转向这个生成，然后去研究生成的文本到底有怎么样的特征，然后怎么样去提升生成的文本的质量，然后就有各种各样的场景，所以基本上现在就 NLP 会有一部分是做这种传统任务的，就比如说分类传统任务，因为还是那样就是分类小模型，它还是在有一些任务上比这种通用性的大的生成式模型效果要好，因为它就是专门用来去分类的，所以它还是比这种通用型的模型会好一些。

Speaker 2 08:08 
然后但是这部分领域它会慢慢缩小，就是一直在缩小，就大家不会去干这件事情，就包括语言学里面有一个领域叫做计算语言学，跟那个自然语言处理就是搞的内容还不太一样。但是即使是因为，即使是像那个就是计算语言学，它更多关注的是语言现象，然后但是它现在照样得用这种生成式的大模型，它得去分析这个生成式大模型产生的这个语料它到底有怎么样的特征，是不是跟人类一些语言的特征是，比如说是相类似或者怎么样的？对，但是就是它没研究的重点就完全变了。

Speaker 1 08:55 
对，没没，我的好奇是就是你在读语言学其实的时候，其实也是跟计算机相关，是吗？

Speaker 2 09:03 
那我开始其实我本身学位是跟计算机是不相关的，但是因为我是走了实习，就是我不是去那个 NLP lab 然后实习的，然后这才跟计算机相关，因为 NLP lab 他们当时在做的是那个 African American language debiasing，就是做那个因为非裔英语和我们学习的标准英语，或者说就是打引号的标准英语，因为这个说标准英语是一个不是特别那个正确的说法，对，ok，就是我们学习的英语或者大众白白人，大众使用的英语和黑人。

Speaker 1 09:55 
哈喽哈喽。

Speaker 2 10:07 
hello，可以听到吗？

Speaker 1 10:09 
可以，怎么又断了？

Speaker 2 10:12 
我不知道，我这个电脑是跟这个是电脑连着，然后我那个我应该现在可以了。

Speaker 1 10:25 
可以，ok。

Speaker 2 10:26 
好的。就是。

Speaker 1 10:29 
什么白人黑人，当时。

Speaker 2 10:32 
对对对对对对，是，就是他们研究的是黑人英语，因为黑人英语其实他算是一种独立的英语，然后语法很多跟白人英语是不一样的。他比如说会省那个省略，那个过去式或者怎么样的？就是白人英语他不可能省略过去式，那黑人英语里面可以省略过去式，那就包括他一些词语的发音，然后拼写的这个变化，然后其实都是有区别的嗯。当然就是黑人英语也在一直影响着，就是咱们使用的英语，比如说那个一般来说是 want to，对吧？就是两个词，但是如果你把它简写成那个wanna，就是就后面加个 NA 的话，那个就是很明显的黑人英语。对，就是比如说汪娜还有高娜，就是全都是黑人英语，但是就是在现在美国英语来说的话，大家习以为常了，也相当于他也，他俩也在互相影响这样，嗯，但是就问题就在于就是黑人英语，因为他不是这个大多数人使用的英语，然后他总会被判定他的攻击性特别强，比如说黑人英语里面会用 n word，就是如果说是我是黑人的话，我可以称另外一个黑人为用那个 n word。这就有点像是兄弟的这个翻译，但是它是没有攻击性的。但又有问题，就是如果一个白人跟一个黑人说 n word 的话，这个就可能会有问题，就是这么一个问题，对，就是他们黑人自己可以说 n word。

Speaker 1 12:13 
对，就是说那时候的研究还没有用到大语言模型，对吧？就那时候还是说已经。

Speaker 2 12:21 
应该说是后期就开始用到了，就后期在做那个语料库扩充，就根据这个音韵学，然后做这个黑人、非裔、美国人英语的这个语料扩充的时候，就因为要让这个大语言模型或者语言模型去适应这个黑人英语，所以就是他必须得去扩充语量，像给他输入更多的这个非裔美国人的这个语言进去，然后让他适应，那个时候就他们加了一个Mixtra，就是也是一个开源模型，是法国的一个独角兽公司搞出来的一个模型，叫做Mixtra。 Mixtra 也是开源的。然后他们当时用在用那个模型，然后 LLAMA 都没有太用，那刚出来，所以他们没吃，然后下来就是T5， T5 就是 19 年的一个模型，当然他们用的不是原本的那个 19 年的模型，他是后又改进了的 T5 的模型。对，然后还有什么就基本上就是这两类，一个是生成式的大模型，就是 Mixtra 这种，然后还有的话就是 22 年之前的这些大的语言模型，但是生成可能不是特别好的。对。

Speaker 1 13:38 
ok，诶，那那，那我们可以具体聊一下，你跟你是，诶，不对，你目前用的是 AI g GPT 的什么版本呀？还是说有变化过？

Speaker 2 13:49 
一直有变化，我是从 3 开始用的，然后 3 它很快更新成3.5，然后到 4 到40，不是后 4 诶，四 4 到 4O 之间它搞了一个。嗯，你。

Speaker 1 14:05 
说没有？没有没有，我是说 4O 然后到 5 是吗？就是说你都是用的 Chat GPT 吗？还是说会用 Gemini 或者是其他的一些 AI 工具？

Speaker 2 14:18 
Jenny 不太用，而且 Jenny 也用它是我在用那个 Colab 的时候就是谷歌，因为 Jenny 是谷歌的，然后谷歌有一个Colab，就是 Colab 就是一种可以在网上跑的一种编译器。对，就是在用那个的时候，然后它会附带 AI 的功能，在那个时候用过，也就是说 Jenny 我只用它做这个coding，然后。对，然后用得比较少哦。现在主要用的是e，其实用的也不是特别多，就是最近就尤其搞科研的话，我们还是比较倾向于用cloud。就是 Claude 模型。

Speaker 1 15:01 
就是说你 Claude 和 GPT 都会用，对吧？

Speaker 2 15:06 
嗯，对，就是不做我的时候两个都会用，然后至于开发的时候就是让一个用哪个？

Speaker 1 15:15 
开发的时候用哪个？我这边有点吵，好像飞机在飞。

Speaker 2 15:20 
没事没事，就是开发的话GPT，然后DeepSeek，然后千问，就这些都会用，就是因为你要测试，就是不同的这个模型，再用相同的提示词或者怎么样，然后在不同的数据集上都得测一遍，ok，然后就都得测。对。

Speaker 1 15:41 
懂了，这就是什么搞代码的，哈哈。

Speaker 2 15:45 
嗯，对对对，就是开发的话那这个就限制不了了，就是让用什么用什么，但是如果说是个人的话就是辅助我个人的。嗯，就工作学习的话，那我会有明显的偏好，就 GPT 可能更多的是让它帮我做一下简单的搜索，然后做一些总结。对，然后的是本身都可以，就尤其是写代码，因为它可以写非常长篇的代码，比如说写 1, 000 多行的代码，它都是可以写的。当然我开的是 Max 版本。

Speaker 1 16:18 
就是 claude 你开会员，那 GPT 你开会员了吗？

Speaker 2 16:23 
GPT 开的是 plus 版，就不对， GPT 开的是那个 team 版本，就是 team 会比 plus 贵一点，然后它每年是能比这个 plus 多一点，并且因为它每年的话最低是开两个号的才能组成一个team，所以就是它会贵一点，所以是算相当于是翻倍的。然后 Claude 那个就是GPT，它不是也有嘛？就是也有一个这个 Pro 的版本，就是 200 刀每个月，你开200，我没有开GPT，我开的是 Claude 的 200 刀那一个月就是 Max 版本。

Speaker 1 16:59 
就是我懂了，就 GPT 你开的是 20 刀不， 40 美刀的那个是吗？然后 Claude 你开的是 200 刀的。

Speaker 2 17:17 
明白。

Speaker 1 17:17 
明白了，就是说你会根据需求来看要不要开会员哈。

Speaker 2 17:21 
对对对对。然后目前的一个小的问题，就是那你用的时长或者这个模型公布的时间越长，它越会可能会出现偷懒的行为，就是它不给你回答，完全会有这种情况。对。

Speaker 1 17:42 
GPT 比较常见这个问题。

Speaker 2 17:45 
对，就是 GPT 开始很常见，所以这就为什么我给 cloud 开了Max，但是 cloud 现在也有这个问题了，但这个问题可以绕过去，你就是你可以强制它，然后输出所有的这个代码，或者说输出所有的文档，这个是没问题的。

Speaker 1 18:00 
明白？这是你的一个使用习惯了，对吧？你怎么去强制它输出？

Speaker 2 18:06 
你可以告诉他，我看你这个代码输出的不完整，你给我把代码补全，然后它就会。但是 GPT 有时候不听你的话，那就是之前的话，我 GPT 不听你的话， GPT 就会给你，还是给你一个片段，它只给你补全，它不把那个补的东西加在它原本的那个框架里面，所以就 cloud 还算是比较听话，那他。

Speaker 1 18:32 
还是可能开的钱不一样。

Speaker 2 18:36 
有可能有，有这个可能性，确实有这个可能性，还有就是我估计跟他们的设置是有关，因为这个如果说是上每个人都让 cloud 播这么 1, 000 行、 2, 000 行代码的话，那他们的这个压力会相当大的。是。

Speaker 1 18:54 
这也是个他们可能考虑的输出的那个 TOKEN 的长度的问题了。

Speaker 2 18:59 
对对对，就是这个，就是用那个UGI，就是用户这个能直接接触到那个界面的一个限制，这也是为什么开发和大家我会有这，尤其，哎，就是直接用后端。

Speaker 1 19:11 
对，但我也发现个问题，就是如果是我 GPT 和那个谷歌的都开了会员了，然后我发现就是在输出的时候， GPT 就是不会输出完整，就是它说啊，我这个太长了，我帮你一节一节输出，然后谷歌的那个就会全部输出，我觉得区别真的是蛮大的。

Speaker 2 19:32 
对，就是就卖那个应该还没到那个限度，就是它还没到那个用户的上限，我觉得，但 GPT 我感觉早饱和了。

Speaker 1 19:41 
有可能就对，是诶，那你比较常用的一些任务有哪些？比如说你刚才提到了 coding 或者是API，然后可能还会有 writing 什么的，还有summarize，对吧？

Speaker 2 19:57 
对，就是如果是问卷上那个问题的话。其实就是除了就是其他模态的，比如说这个 visual 的，就比如说 picture generation 这个不太用，或者 video generation 我也不太用，然后 Audio generation 我也不太用，就是这些我都不太用，我主要是作为就是用那个文字的生成。嗯，没问题，这个比较多。

Speaker 1 20:21 
那可以具体聊一聊，比如说要不然一个一个聊，比如说writing，你 writing 会用到什么样的任务上？

Speaker 2 20:30 
writing 的话，比如说写文章的话，现在写文章我不会说是自己完全先写一个非常完整的草稿出来，然后让再让他帮我修改，而是我会先把，比如说这个段落的大纲列出来，我要先说什么再说什么，然后具体哪一步需要注意什么，然后这个写出来，然后告诉他，让他帮我写出一这么一个自然段，然后再去看他写出来这个自然段，我再修改，然后这就是最终的成稿。

Speaker 1 21:02 
对，这个有个问题，就是这个自然段，比如说你现在要写，比如说就写那个 edu prompt 那个，那你是，对，是会跟他讲背景呢？还是说就直接地跟他讲这个段？我的开头。什么？你要注意什么？还是说就是你整个流程是什么样的？

Speaker 2 21:26 
这个不太一样，就是如果说是开头的那个段，开头那个段不是要做一些背景介绍嘛？像那种背景介绍，我就基本上让 GPT 去帮我找背景的，因为第一段背景介绍没人会看，但是它又必须。

Speaker 1 21:41 
得有。对，那相当于就是说你会根据不同的自然段，然后你的处理方式也会不一样。

Speaker 2 21:50 
对，然后比如说就是不需要做任何引用的话，那其实我知道这个段要干什么，我直接告诉它就可以了，然后我把数据给他，然后让他帮我写就可以了。

Speaker 1 22:04 
那会不会出现可能他用的某些词？ GPT 很常用，然后就可能会被什么查到什么的。

Speaker 2 22:16 
就怎么说，因为我不用 GPT 也就靠的能好一些，那在这个频长频词上面肯定会好一些。还有就是我一般会给告诉他，就是我让他先帮我写出来了一版，我发现他的这个语气或者怎么样？特别的生硬，或者怎么样，我会告诉他就是 be natural。然后 clarify the details，就是用这些词就更像人一些，并且就是比如说就在细节上面你需要clarify，然后扩写哪块需要再扩写一些，因为人的话他是知道重点的，所以他知道哪一块是可以扩写，哪块不需要扩写，所以我只需要按照我觉得哪一块需要扩写，哪块不需要扩写，然后告诉他，让他帮我扩写就可以了。

Speaker 2 23:03 
就是整个应该说是，我大概就是写作的时候，其实大概脑子里面有个大概的结构，但是中间的很多细节都不是特别清晰。然后我把这个大概的结构输入给他了以后，他先帮我产生了一个比较细节的这么一个，嗯嗯，就你一段话，假如说一段话，然后我发现有一些步骤他写得特别的粗糙，嗯，然后需要某一些需要再细致一些，或者说某一些写得特别细致，我不需要他这么细致，然后我会告诉他，就这一块你缩写一下，这一块你详细写一下，然后这块的这个数字符号的表示不太清楚，你帮我把这个数字和表示说明一下，我会这么样告诉他。

Speaker 2 23:45 
所以就是这怎么说呢？就是其实写出来他确实会有一些高频词了，就是高频词是很常见的，就是现在你也没办法分辨这个高频词到底是人在使用还是跟 GPT 在使用。嗯，这确实，嗯，对，就是我觉得更多的是人会通过就是行文的风格，比如说这个文章的节奏的说明的节奏的把控，然后我去那个啥，就是去辨别这个到底是不是 AI 写的。

Speaker 1 24:17 
哦，那比如说你这些段落写好了，那之后是比如说都丢进去吗？还是说因为你因为肯定会有点不顺嘛？就是肯定逻辑上因为是一段写的，会让他再重新帮你看一下逻辑什么的吗？

Speaker 2 24:33 
对，不会让他帮我看，我会自己看，就是他输出一段，然后我现在就该我来该写就中间怎么样过渡呀？怎么样写呀？这个是我会搞的。

Speaker 1 24:44 
明白，就是说之后的反正就段落他写，然后之后你会再修改完善，然后拼起来。嗯，对，是这样，明白，那对于writing， wri- writing 就这么这样的任务吗？还是说还有一些别的任务形式？

Speaker 2 25:02 
比如说写邮件？嗯，写邮件基本上他给我写。

Speaker 1 25:07 
然后。

Speaker 2 25:08 
现在差不多了。对，那个就是我会告诉他这个邮件我要表述什么，你帮我写这么一个邮件出来。

Speaker 1 25:16 
对哦，明白，就是说你，然后我再改你，你是这样就是说什么啊？这封要发给谁的邮件？然后内容大概是什么，对吧？然后，嗯，那这个邮件你是你用的一般是用英文跟他对话还是用中文跟他对话？

Speaker 2 25:31 
嗯，一般来说是英文，然后中文的话我会用DeepSeek，就是中文的话基本上都是写微信的，就是写微信的这个发微信的这个祝福语或者怎么样？这个用DeepSeek。OK。

Speaker 1 25:45 
没有，因为我其实有一直有个问疑问，就是在使用 CHAT 又或者Claude，因为他们一直说对于英语输入和对中文输入会不会有一些偏差？我因为我是没感觉你，你有这种感觉吗？就是可能你英文输入它反馈的结果会更好吗？

Speaker 2 26:12 
对，他又断开了。

Speaker 1 26:17 
都没听到，是吗？我就是。

Speaker 2 26:19 
我，我听到了，没事，我。我能听到好像是断开的话，你听不到我说话？对，稍等一下应该可以了。ok，就是反正断开了，然后你就听不到我说话了，我会重新说，没关系，好的，不好意思。对对，不好意思，不好意思，这个东西这块网不太好，我只能用流量。

Speaker 1 26:45 
没关系，没关系，就刚刚说到什么，哦哦，对，就是偏差的问题。

Speaker 2 26:52 
嗯，我感觉的话 cloud 和 GPT 中文的话差异不是特别大了，就是因为我用 cloud 和 GPT 基本上都不用中，所以其实我不是特别清楚它俩的这个中文语言表述到底怎么样，但是我能感受出来的是 cloud 就 GP 这一类的模型跟 DeepSeek 去比的话，在中文语境下就会差得比较大。对。

Speaker 1 27:25 
就相当于说因为可能也是语料的问题，就是他们抓国内的语料肯定没有 DeepSeek 好抓。

Speaker 2 27:33 
对，就是因为你这些模型，基本上你给他输入的东西你就默认，除非他会告诉你我们不用你的数据或者怎么样，然后他不说我们不用你的数据，或者是不让你选可不可以用你的数据，这种都是用你的数据的。明白？ DeepSeek 就是默认就是肯定是会用你的数据的。

Speaker 1 27:52 
但 DeepSeek 我觉得有个最大问题就是它的幻觉特别严重，你有感觉到这个问题吗？

Speaker 2 28:00 
嗯，因为 DeepSeek 我基本上都是用来写那个啥，哼。哦，写祝福语。

Speaker 1 28:06 
哈哈，明白明白。对。

Speaker 2 28:09 
我不是特别会让他去帮我干活，因为我感觉这个是幻觉，是必经的一步，就是g， g 就是 GPT 之前不是也有一阵子幻觉特别严重嘛？

Speaker 1 28:23 
对。

Speaker 2 28:25 
然后现在就还好。

Speaker 1 28:27 
那会不会存在我，我可能是之前的访谈中存在这么个问题，就是比如说他换解这么多，然后或者说用户会不会对 AI 产生一个上瘾的一个机制呀？我我我是说从你的教育学角度来看。

Speaker 2 28:42 
那幻觉就是 AI 的幻觉，它是应该说的是那个产生不真实的输出，就是它个输的输出跟现实不相符，对。

Speaker 1 28:52 
就是这个是幻觉，对，我就觉得会有出现错误的引导，然后导致用户可能会对这种引导可能会比较上瘾，就是可能。嗯，我觉得可能在心理支持上，或者在什么支持上的时候会不会出现这种问题？

Speaker 2 29:10 
就是它确实会产生那个 account is all flow 的，就是这个 all flow 的其实跟幻觉没有直接的关系，它只是因为就是 GPT 在表述的过程中，它表述得特别的官方，特别的正式，然后就造成了一种它非常权威的假象，然后人就信了。

Speaker 1 29:32 
好像我在哪个报告上看到说因为 GPT 产生的流畅度太高，导致人就会相信它所有的表述，这好像是某对不很写。

Speaker 2 29:44 
对，我觉得人会考虑这一点，就是如果说是他前文不搭后，就前后的这个意思都不太一样的话，人不会相信，那就因为他是根据之前的输出或者之前的这个记忆，然后去输出后面的内容，所以他一直都是相关的，他相关性很高，他前后文的相关性特别高，这就导致人没办法去鉴定他到底知道不知道，因为人之前就是鉴定我，假如说你鉴定过我到底可不可信的时候，嗯，你会观察我说话到底有没有逻辑性。嗯，然后我的这个，这说话的内容能不能说服你？然后甚至有可能因为咱们俩专业不太一样，对吧？然后我说的一些话可能你压根不懂，但是你能感觉到你到底能不能相信我？因为你是会去衡量我说话中到底有没有逻辑。对，就是前言不能前文不答，后面的这个。

Speaker 1 30:43 
后文。对，对。但你。

Speaker 2 30:45 
就是你有一个基础的判断。对。

Speaker 1 30:47 
对，但你提到一个很关键的点，就是熟悉和不熟悉，就相当于比如说我现在，比如说就想去了解AI，就比如说假设就了解计算机某些方面的知识，然后再 chat GPT 输入了，对不对？但是我又不是很懂，那我不就是会相信它所说的东西吗？那假如是商科或者是某些方面我了解的知识，然后去跟它对话，我就能看得出它有些不一样的点。

Speaker 2 31:14 
嗯，会不会是这样的？所以就是，嗯，您，您说。

Speaker 1 31:19 
没没没，我就想说就。就是说那这样不就会出现所谓的，就是我也没办法去判断他的前言后语对不对？因为我本身也不太懂。

Speaker 2 31:30 
对，这不就是为什么人会被传销？哈哈哈，因为我也不知道他到底是不是说的真的，我就觉得他可信，所以我就信了，然后我就开始进入这个庞氏骗局。

Speaker 1 31:42 
明白，对，所以意思就是说这种东西其实不可避免的，对吧？就是因为我本身就不熟悉，我也只能完全信任。

Speaker 2 31:51 
对，也就是不熟悉，所以完全信任。但是还有一种破局的方法，就是你对 AI 非常熟悉，你知道他在某种情况下容易去产生不正确的信息，所以你不给人，不让他去干这些任务，这是破局的方法之一。

Speaker 1 32:08 
对，明白，就是其实有些任务就是他肯定造假程度比较高的时候反，你觉得会，一般会有什么样的任务会出现所谓的这种问题啊？大概是什么样的任务？数学我第一反应是数学。

Speaker 2 32:26 
数学其实还好，因为数学现在测的特别多，因为他们现在做那个大模型推理的时候，用的数学和代码这两种任务，基本上就是用这两种任务去做那个大模型推理的，所以其实还好，就推理模型其实都还好。嗯，但是问题就在于它如果说是遇到了不熟悉的领域，就是推理它是整个逻辑是连贯的，但问题是很多场景下的很多问，就是很多任务它逻辑是不连贯的。比如说我说，就或者不是说是逻辑不连贯的问题了，而是有很多隐藏的信息。就人他是有这个，有对这个隐藏能力，就隐藏信息的这个理解能力。就比如说最简单的就是日语的话，它是对于上下文，就是你理解一句日文的话，它可能更多的是要理解这一句话在上下文之间的这个作用，然后你才能理解到这句话的含义，就是你如果没有上下文的话，很有可能你这句话理解错了。

Speaker 2 33:35 
日文就是一个语境语言，它必须靠语境，然后去理解这句话。中文也是偏语境的，但英文不是对英文的，对语境的这个要求会低很多，就是它整句话它可以独立存在，但是中文和日文在有些话里面就不太行，就尤其是日文，它对于语境的要求特别高。然后语境这个东西相当于是你的，就是人的这个 prior knowledge，它不是一个，就是显性的，它可以直接输入的一种knowledge，就是我甚至都不知道我有这个经验，但是我脑子里面已经有这个经验了，所以我可以通过这个语境推导出来这句话到底是什么。嗯嗯，但是大语言模型如果说是没有足够的训练的语料的话，它是推导不出来的。

Speaker 1 34:25 
我大概能对。

Speaker 2 34:26 
像这种。

Speaker 1 34:27 
对，就是说你背景信息不够的情况下，它其实是没办法去理解对的。对，就因为对日语就属于那种，你需要提供很多的背景信息以及上下文的一些关联，它才能很好地去理解你是表达的意思。

Speaker 2 34:47 
那也就是一个是这个，还有一个是，嗯，就是如果说是，这是一个非常非常复杂的任务，就比如说我问GPT，当然就是这个任务跟现实是有关系的。假如说我问GPT，我造一栋楼要怎么样搞？就是我完全不给他提供任何信息，然后我也不告诉他造的是什么样的楼，他会生成的，他确实是会生成，怎么一个造楼？但是你要说造炸弹他不会，就是造楼他是会的，但是他跟现实的这个差距就非常大，一个是他缺乏信息，对，就是一个是缺他缺乏信息，还有一个是这件事情非常复杂，他没有考虑到所有的情况，如果说是一个就是非常有经验的一个建筑师的话，他在考虑造一栋楼的时候，就你如果问一个建筑师怎么样去造一栋楼，这个建筑师会反问你要造什么样的楼？具体有什么样的这个功能或者怎么样，建筑师是会问，因为他脑子里面有多种方案，他不知道你在说哪一种，但是对，就是模型他是没有，他会只会给你输出一个。

Speaker 1 35:54 
明白，就是就是。嗯，你，你说。

Speaker 2 36:00 
对，就是他，你可以让他说出输出多个，但是他不会意识到他输出的这些内容，他不会去验证他输出的这些内容到底和你说的这些东西是不是相符。对，他没有 Meta cognition，就是这个意思。

Speaker 1 36:16 
我觉得他可能更像是一个服从性的，就是他并不需要去考虑你的，就是可能也是我们提供的信息不足，但他也不太嗯 care 你到底足不足，就是他也不用考虑这件事情真实性就能不能完成，可以这么说。

Speaker 2 36:33 
对对对，就是人在说话的时候，我觉得大家都知道自己说的哪些是真的，哪些是假假的，起码就是知道哪一些是自己相信的，哪些自是自己不相信的，对吧？就是这个是属于是说话内容的一个属性，嗯，人是有这个对这个属性的掌握的，然后但是大模型它没有，就是它不会说是去先去想我说这句话到底我相信不相信它不会去想这个问题？没有这个功能。

Speaker 1 37:08 
但好像这可能是后续的，就因为可能是不是 TT 反问一句，诶？那你具体的目标是什么呀？那你到底是为了什么？群体还是建的楼，对吧？就是多问几句，可能反而用户他就会更加表达自己的需求，这些可能，对。

Speaker 2 37:26 
吧？对，是这样的。对对对，就是，但是，嗯，就这块需要注意的点就是他反问，他不是说是自己觉得应该反，就是自己认为有必要反问，有一必要去验证一下，而是他学习的是这样，就是人告诉他你必须要反问，或者说训练语调里面基本上最后会带这么一句反问的。

Speaker 1 37:48 
明白，所以他这么反问明白，所以可能在我们之后，比如说智能体的考虑中，就有些就专门干这种事情，有些就是去做别的事情，这样分工的话可能会出现一些不同的。叫什么？叫不同的感觉吧。

Speaker 2 38:06 
对对对。

Speaker 1 38:08 
对。ok，这刚聊的是属于一个 writing 以下的任务，也算是 writing 以下的任务。那除了 writing 刚才提到的有什么来着？ coding 还是就是。

Speaker 2 38:23 
coding？对，coding。

Speaker 1 38:25 
哦，诶，不对。刚才提到还有一个跟 writing 比较相像的，就是summarize，就是总结，是吗？你是会让它总结文献还是总结什么？

Speaker 2 38:34 
到时候不会让它总结文献？我基本上现在用，比如说GPT，直接是上网搜帮我爬文件也是这种，那个 AI 给你。 AI powered searching. 然后就开始的话比较多用的是比如说perplexity，就这个也是一个 AI power 的一个 search machine，然后它主要就是做 searching 的，帮你去 search 各种的东西，然后后面逐渐的像Claude、GPT，然后DeepSeek，就是这些他们都会有这个 searching 的功能。所以其实就。

Speaker 1 39:09 
你是说那个搜索功能吗？还是我，我都没有用过，是哪一个啊？是 Web search 吗？

Speaker 2 39:20 
对，就是 GPT 也有，然后我不知道Germany，但是那个 Claude 也有，但是它会帮你去搜索。

Speaker 1 39:27 
但这个搜索的话我有个疑问，就是它一定要点吗？我好像就算不去点这个功能，然后输入帮我在网上搜一些信息，它好像也会去干这个事情。

Speaker 2 39:39 
嗯，对，就是只要你不关这个功能，它就会用，它觉得需要用它就。

Speaker 1 39:44 
会用，就是它自动调用，是吧。

Speaker 2 39:48 
嗯，对对对。

Speaker 1 39:50 
ok，你说的意思就是说这个是属于一般搜什么样的资料的时候你会用到它呀？是比如说了解一个领域，还是说只是当前需要一些资料来帮你写什么东西的时候。

Speaker 2 40:05 
我其实就是我已经知道了，我要做就是了解这个领域，然后会帮他，我会让他帮我搜文献。就这个领域里面有哪些引用量比较高的文献啊？你帮我搜出来或者说是有几个大类，这个大类的下面有哪些代表的文献？你帮我搜出来这样。

Speaker 1 40:24 
但会不会有个问题，就是在搜文献的时候会出现文献不正确，或者是说文献有遗漏，这些都是没关系的吗？还是说现在已经。

Speaker 2 40:34 
有遗漏是肯定的？对，就是遗漏是肯定，他没办法防止，就是有点像人。他在总结人的文献，第一就是人，他也没办法把所有一个领域里面的所有文章全都给你搞出来，就是没有办法做到完全没有遗漏。还有一个就是他是有限制的，因为我觉得我记得那个Claude，他一个对话框一次，一次搜索只能搜索五六次，好像有这么一个限制。哦，明白明白。那，那他然后说到你说没？

Speaker 1 41:07 
没，你说。

Speaker 2 41:10 
对，因为我就说没，没回答完。因为这个除了移动之外，不是还有一个错误，完全错误。就是这个其实现在很少，因为他会给链接，就是他会给那个他搜索的这个网页的网址的链接，你可以直接点那个链接，然后过去查看。

Speaker 1 41:27 
对，明白，就是说这些就是以前存在的那种虚假文献，在现阶段其实都已经被完善。

Speaker 1 41:43 
啊，没没没，刚刚好像可能小小断了一下，我听到。

Speaker 2 41:49 
那个。对，就是现在因为有了搜索功能之后，他其实不会说是在这方面有特别多的幻觉，就是他这边的幻觉会少一些。

Speaker 1 42:01 
嗯嗯，那对于其他你刚才说 coding 的话，你是让他写代码，那这种情况下就是说你会给他让他写一个一个完整项目的代码，是吗？还是属于你会分工之后让他写某些模块的代码？

Speaker 2 42:20 
基本上是让他们帮我写完整的代码，因为完整的代码也就 1, 000 多行，所以也不是说那种完成不了的，哈哈，工作量，所以就是我会告诉他这个代码我要干什么呀？你需要调用什么样的模型？然后具体这个，比如说是提示词的工作的话，那就是这个提示词该怎么样去写？甚至提示词我都自己不写了，就是我会告诉他你用哪种技，就是技哪种技巧去写这个提示词。

Speaker 2 42:47 
比如说用那个 chain of thoughts，或者说是用其他的一些不同的这个写 prompt 的一些格式，或者说是这些 agent 之间有怎样的沟通？就是他的，他之间的这个交流是怎么样的一个交流方式？然后你只需要告诉他，让他去帮你完成就可以了。

Speaker 1 43:09 
所以说就是其实你已经很清晰地知道你这个项目每一块是什么了。就是说也不需要的话， AI 来给你构思这个项目中的某一些部分需要怎么去实现，就是就没有一些是那种 brainstorming 的，就是说头脑风暴上的一些事情，对吧？他只是一个执行者。

Speaker 2 43:30 
头脑风暴我用得很少，我觉得就个位数，因为好像我能记得的就一两次，就好像就是感觉没有太多的灵感了，就问一下他这样或者说是实在不知道？嗯，就是对，实在不知道用什么模型了。问一下他，对。

Speaker 1 43:50 
但其实就是说你还是会自己去读文献，然后去看最新的研究，然后去构思你的idea。可以这么理解吗？其实因为GPT。

Speaker 2 43:59 
我其实不看，对，我是不看的，就是我只会去看一些非常相关的跟我这篇文章非常相关的文章。比如说就是最近的一个baseline，然后它的这个因为我要通过最近的这个baseline，然后去找出这个 research gap，然后这个 research gap 是我必须得自己找到的，就是 AI 很难帮我找到一个非常好的哦。但是其他文章我都不看。

Speaker 1 44:29 
但我有个问题就是说比如说 edu 这一篇，那你的 idea 的就是第一步的出来是跟 AI 交互，还是说自己去就是看到了这篇文献，然后想到了 gap 是哪一种方式去完成这个的？

Speaker 2 44:46 
我觉得更多的是我自己有一个idea，然后这个 idea 可能并不来源于我去做文献综述，或者而是我就发现有这么一个需求，然后可以这么样去做，然后我去查了一下，没人做，是吧？你那我来做，或者说是别人做了他有什么样的缺点，然后去解决这个缺点，更多的是这种。

Speaker 1 45:07 
明白，所以相当于更多的是自己的想法灵光一现，对吧？就自己的突然想到可以这么去构思。

Speaker 2 45:17 
对对对，然后极少的情况，比如说我看见了一篇文章，然后我觉得他的这个方法有哪一些的缺点？然后我去改进，但是这种就是他的创新性会低一些，就这种创新性都会低很多。对，嗯。

Speaker 1 45:35 
那其实相当于，其实这些你已经构思清晰了，就是说每一步的逻辑你也很清楚，然后这时候，然后让 cloud 来把你所有代码写出来，可以这么理解吗？那会不会有问题？就是这个代码可能会，比如说中间有些步骤他写错了，或者是导致就跟你想的不太一样，会有这种这些问题。

Speaker 2 45:58 
我这种问题就是这种问题，其实你很好看出来的，要不然这个代码跑不起来，就是他很乘客是有问题的，跑不起来你让他修改就好。还有一种是你会发现跑出来的这个结果跟你想象的差别很大，就因为这个你可以让他写代码，然后让他把所有的这个 input 或者output，每一步骤的 input 和 output 全都是，就是打印出来， print out 出来明白，然后你就能看到，然后你只需要看这个 print out 就可以了。

Speaker 1 46:30 
是，所以相当于就是说这种反而就是能够节省你比如说一大堆的代码之后，然后发现也不知道哪里错在哪里，反而每一小部分写一个print，对吧？就可能可以，对。

Speaker 2 46:43 
对对。

Speaker 1 46:44 
ok，ok，是对，对于这个就属于coding。那 coding 一般就这种任务上，是吗？还是说还会有一些别的任务上？

Speaker 2 46:57 
那个怎么说呢？就是现在做的跟提示词相关的，或者跟大语言模型相关的，就是基本上 coding 都可以直接让它帮忙写，但有一类的没办法让它帮忙写，就是你做模型本身的创新的时候，这个是没办法让它帮你写的。

Speaker 1 47:16 
但模型上的创新这是应该比较难了，毕竟这种东西需要各种的 GPU 或者是，对吧？就要训练它的model。

Speaker 2 47:26 
其实也不一定就是我刚才我不是说有一类非常，就是现在这个领，这个范，就是这个领域越来越小，但是它还是存在的，就比如说做一些小模型，然后小模型你必须得去把这个小模型的一些已经不是调参了，把它的结构给它。嗯，调整，因为其实说是模型，但是它其实咱们更多的说的是那个学习的过程，然后这个学习的对象到底是什么？怎么样去学习？然后这个每个 neural 和 neural 之间的是怎么样去连接的？这些都是可以改变的。嗯，然后就是做这个的时候，你必须得明确你到底想怎么样改变，你改的是第几层？然后比比，或者说是你到底让他学习的是什么？然后你让他做 embedding 的话该怎么样去做？就这些你必须得非常的明确，然后你才能让他去修改，也是可以修改，就是他也是可以修改的，但你必须非常明确。

Speaker 1 48:25 
明白，所以说我觉得好像更多他都是处于一个执行的阶段，反而不会对，他并没有说给你产生一些好的idea，比如说你的那个论文中会说不，比如说把这个输入这一层，然后再把他们两个东西输入下一层，对吧？这种东西具体可能就没办法去给到你一个好的idea，对吧？

Speaker 2 48:48 
对，就是这个，也是刚才所说的，就是他没有这个 Meta cognition，他没有这个概，就是没有价值的概念嗯。嗯，他没有价值，就是人是有价值，人是知道好坏的，所以他是有价值。对，就是他是知道这个，有这个价值观，但他是没有价值观，他不知道什么东西值得做，哪些东西不值得做。

Speaker 1 49:09 
明白，其实有点类似于，比如说我们提出了多智能体，然后这时候需要一个理论来支撑，他可能可以这种，我觉得反而他可能可以给一些，因为理论都现有理论，我觉得这种时候他反而能提供一些brainstorm，或者是应该叫信息检索，这种东西应该算信息检索。对。

Speaker 2 49:31 
是，就是只要有方法论他就可以执行，或者说是有一步一步的这种明白方法的，或者说是这个 chain of source，然后他就可以执行。对，但如果没有的话，那就比较难了。对对对。

Speaker 1 49:45 
所以 idea 还是掌握在我们手里面的。对，然后他还是更多是一个执行者。那对，就其实我比较好奇，因为就我觉得你已经完全偏计算机的方向去了，那假如就因为可能之前我访谈过教育学的，他说就是可能会把它当做一个学生，然后跟他很有耐心地去跟他沟通指导，可能这时候他说会产生一些比较有趣的idea，这是这可能你还没有接，可能你不会这么去用它吧，对吧？就是这种方式的话。

Speaker 2 50:22 
我会觉得就是它给我就是在交互的过程，当然交互过程中然后我有了灵感，这个也是正常的，就是我只不过是这个我交互的对象，就我的交互对象不是AI。我交互对象可能是其他的文献或者怎么样，就是那可能其他人他可能交互的是AI， AI 也是有这个文献的训练的语料的，所以他可以提供一些就是文献里面的一些观点或者立场，然后这个学生他就是他在做科研的时候，他先跟 AI 去交互，然后先去就是去探索，然后慢慢地把这个他的 research question narrow down，然后成为一个可以研究的这个 research question，这个是可能，嗯，这个是肯定可以的。明白，但我不需要，就是，呵。

Speaker 1 51:10 
对对，这这肯定根据每个人的需求来说还是不一样的。对。

Speaker 2 51:16 
对对对，就是他是有这个能力的，就是他没办法直接告诉你什么是有价值或者哪个这个问题该怎么样去 narrow down，什么东西值得去做？他没办法告诉你这个，但是他可以帮你去。

Speaker 2 51:30 
To brainstorm, need to brainstor.

Speaker 2 51:32 
我们就可以了，就把所有的相关信息全都给你罗列出来，这个其实它是可以的。

Speaker 1 51:36 
是明白。然后刚才说到除了 coding 还有一个是还会有什么样的任务 API 吗？你是想说这种。

Speaker 2 51:48 
但是我就。

Speaker 1 51:50 
但我觉得 API 这种写的方式好像看不出来交互，对吧？这种好像看不出来交互。

Speaker 2 51:58 
也不一定就是这个，就是你用 API 的话它也是需要交互，就在测试阶段，你要测这个 pump 到底合不合适，或者说是这个 agent 和 agent 之间的交互，它能不能让这个表现最后的 performance 最大化啊？就是会测这些。

Speaker 1 52:17 
但这个的交互好像不是人人机交互嘛，对吧？好像更像是技术层面上的交互了。可以这么理解吗？

Speaker 2 52:26 
对对对对，就不是那种人机交互，比如它不是说是为了你达成一个目的，而是我为了达成这个目的，然后我用了这个工具去搭建，仅此而已。对。

Speaker 1 52:40 
那比如说还会有一些什么样的任务？就你觉得你常用会用 GPT 去帮你完成的。

Speaker 2 52:52 
基本上比如说现在感觉，比如说搜索或者怎么样，我就会让 GP 帮我搜索，就我不会用谷歌浏览器，或者说是用得稍微少了一些。对。

Speaker 1 53:08 
明白，就是说也就是信息检索，把它相当于快速帮你整理你想要的东西。

Speaker 2 53:15 
嗯，对，是这样，然后其他就没啥了，我基本上不用它生成，就是图片声音，就是那个 Audio 啊。什么？就是我不用这些。

Speaker 1 53:27 
明白，然后我想想，诶假，我其实有个疑问，比如说因为其实，嗯，就其实对于我们这一类群体，就是硕博，就是其实他我们的 critical thinking 能力都比较高嘛。那假如说，对于，比如说你可能，比如说比你低的学弟学妹，或者说你可能你指导的学生，或者说就那种 critical thinking，你会鼓励他们去使用 AI 吗？

Speaker 2 53:59 
我觉得他们已经是 creative thinking 之前的问题了，就是他们的积累过于少，所以他们必须得靠一 AI 去快速地就是完成原始积累，就是知识的原始积累。嗯，就是我觉得他这个 creative thinking 可能更多的是，就是我了解了很多知识，然后我在看到新的领域的时候，然后我突然就是，当然这个不是有意识的行为，而是我，嗯，脑子里面觉得这个场景跟我之前接触的某一个场景非常相似。然后我就会去类比，然后去这个思考明白。

Speaker 1 54:35 
对，这好像是，这应该是属于我发现另一个，就是从你这里发现另一个点，就是说通过 AI 来学习新的知识之后，让自己的知识领域扩增拓增嘛。对，然后增加之后你就能去判断这些东西写得怎么样，但也会出问题，就是他假设就是完全也不懂，比如说你可能再带一个本科生，让他帮你写把，去写一篇文、论文，对吧？或者说让你去让他去总结个什么东西，就发现就是个 AI 生成的，那这时候不就会出现很不具有 critical thinking 这么一个能力吗？

Speaker 2 55:13 
对，我是我们会觉得就是把这些任务直接交给他，就本身这个事就是我的这个判断本身可能是有错的，就是我不会，我尤其是本科生的话，我会让他执行那种非常简单，只需要摁两个按键就可以执行的，就是比如说直接把代码就是复制过去，然后复制到那个服务器上面去帮我跑一下，然后只需要他干这件事情，然后把这个结果记录下来就可以了。然后至于修改的话，对，我修改的话我基本上都会告诉他们怎么样去修改，就是这个我想让你帮我改成什么样？具体这块可以改，那块可以改，具体怎么样，改好了我把这些事情全告诉你了，你可以交给 g GPT 了哈。对。

Speaker 1 56:00 
那其实这个事情有点像，我给你规定好了你的任务、工作要求等等这些条条框框，然后其实你相当于就是说他去帮你校对 GPT 输出的内容是否符合你的条条框框。

Speaker 2 56:16 
对对对对，就是他只是有点像是这个对像，那只不过是监控一下就。

Speaker 1 56:22 
可以。对对对，相当于他没有处在一个需要他 critical thinking 的这个层面上的一个问题。

Speaker 2 56:30 
对，我就是刻意的不让他。去做 creative thinking，因为我不知道他 creative thinking 出来的东西到底是啥。

Speaker 1 56:35 
所以对，白明白，就是我懂了，就属于这个监控层放在了自己手里，而不是而不放在他们那一块那。嗯，但是假如说，比如说，就是比如说你在带一门课，然后你布置了个作业，然后你怎么去防范，或者说怎么去避免？尽量地避免他们所交的答案都是 AI 生成的。即使你说了你们不要用 AI 去生成，但他们肯定还是多多少少会去用的。

Speaker 2 57:04 
我会生，我会给他们布置那种 AI 没办法很好执行的任务，但对，就是他必须得自己去想才能行，比如说他自己得，必须得确立这个他研究的目标，因为 AI 他如果说是研究问题的话， AI 提的研究问题会非常非常的Vague，就是他不是一个可以研究的问题，他的要不然他输出的那个研究问题会非常长，但是我们不需要那么长的研究问题，就是一下子能看出来，要不然就是他会输出得非常vague，就是他就那么短的一句话。然后他也没有，就有任何可以值得研究的点，就是它的范围太大了，所以研究不了，就 AI 会生成这种，就是这就一下就能看出来了，那很明显就是你就算，就是这个学生，他就算全用 AI 去生成了这篇文章，再用我一看我就知道这个不合格嘛。你不管它是怎么样，就是 AI 它也是不合格的，就算是他自己写出来的也是不合格的，就没有关系了。

Speaker 1 58:08 
那这种你一般会比如说会更相更倾向于 coding 呢？还是 writing 呢？还是就这种一般会是像什么样的任务？应该是开放式的。

Speaker 2 58:21 
对， writing 会多一些，就是其实 coding 很难去杜绝他们用 GPT 的。

Speaker 1 58:27 
要 o 应该难杜绝的是 coding 这种东西代码能力肯定，我觉得 GPT 的能力肯定是比人强的，就在 coding 上。对对。

Speaker 2 58:37 
那起码比本科生强。那其实。对是。

Speaker 1 58:41 
我觉得其实大家其实已经不管硕博，反正大家很多代码任务都会让 GPT 来完成了，基本都是。

Speaker 2 58:48 
对对对，是对。

Speaker 1 58:50 
那你就是，嗯，您说没有？你说。

Speaker 2 58:55 
没有？没有没有，我只不过是一个comments，你要是下一个问题的话，你说下一个问题。

Speaker 1 59:00 
对，我其实就是有个问题，就是完了打断，等一下让我想一下。

Speaker 2 59:07 
嗯，好的好的。

Speaker 1 59:16 
刚刚才是说到什么来着？突然断了。哦哦，该说的那我没，那还挺对的。嗯，那比如说什么样的？比如说是那种，比如因为我之前就在想这个实验任务一般会定到什么样的一个程度，然后让他们会没办法只用 AI 就能完成。然后我就想，比如说政府颁布了什么，什么什么一个政策，你然后就开放式讨论嘛？或者说在校园里面实施 AI 监控会不会侵犯什么什么权益？这种就这种会不会很开放导致这样？但我又觉得 GPT 好像也能给出很多观点。

Speaker 2 59:57 
对，就是我觉得更多是可能咱们这个后面培养学生的时候考虑的是，如果是 GPT 会干的，我就不要求学生一定会自己干，因为你防止不了他跟 GPT 合作，但是有一些东西目前是 GPT 没办法干的，但是如果说 GPT 有这个原认知，或者说是怎么干，他也是可以干的，就是你这理论上是可以取代的，就是理，只是现在目前来说是理论上是可以取代的，就有可以有一些可以取代这个本硕博以下的，这个这些就是人。对，但是当然他以后会取代博士的，这是肯定的。就是那我觉得更多的是怎么样培养学生跟 AI 去协作完成一件事情，他只需要知道这个，这件事情该怎么样去，就是什么是好，什么是坏，我觉得就可以。

Speaker 1 01:00:51 
了。明白，所以这个实验任务的具体制定也可以后续再讨论，对。

Speaker 2 01:00:57 
不对？对对，是的，就是以后也许他不需要知道，就是 1 + 1 = 2，然后或者说是 8 × 8 = 64，就是他不需要背那个乘法口诀，他只需要摁一下计算器，或者说是问一下GPT。明白就可以了，但是他必须得知道就是怎么样去判断是不是对的，就是他可以跟 GPT 合作，但是他如果和 GPT 合作下来， 8 × 8 = 72 的话，那这个，哼，那我得让他知道这是错的。

Speaker 1 01:01:28 
对，明白是能理解。能理解诶，那你有没有就因为你刚才也提到了那个，那个 chain 是什么？我突然间忘了。是那个思维链的诶，计算机怎么说来着？那个，对，椣树那个 chain of thought，对对对，就计算机中这种，你是不是也是接受过提示工程的培训，或者说学习过相关的知识？

Speaker 2 01:01:54 
嗯，没有这东西纯粹靠自学，就是提示词怎么样写，我觉得现在目前还是你得尝试，因为有一些情况下就是 chain of source 不是一个最佳的策略，他可能你直接提问就可以了。对对对，然后让他回答。

Speaker 1 01:02:12 
我，我好像也遇到好几个人跟我说，就是现阶段好像就跟他讲个简单点的东西，反而他输出的东西更好。

Speaker 2 01:02:21 
对，就是他的灵活，就是他会，就是有点像是你如果让他走那个 chain of source，或者是说走这个 Multi agent 这种框架的话，他会限制他的灵活度。然后很多时候就是人在我在设计这个 chain of source，或者说设计这个多智能体的时候，我不会考虑到他可能需要某些的灵活度，嗯，我可能没考虑到，但是实际在测试的时候我又需要是，然后这就是为什么它不太好？对。

Speaker 1 01:02:54 
是这样，那就比如说用 GPT 来说，你觉得会对你的思维深度有变化吗？还是增加啊？

Speaker 2 01:03:04 
应该。嗯，增加，可这个肯定是正向增加，它不会说是减少，但是写代码的时候也会，也许会那个 call native offload 也会，也许可能是这样的，就是。对对对，就尤其是我不熟悉的东西，我越有可能会offload，但是熟悉的东西我不反而不会offload。对。

Speaker 1 01:03:29 
是这样的，就所以还是根据那怎么说来说去都是属于那种这个知识到底是熟悉的领域还是不熟悉的领域？

Speaker 2 01:03:38 
对对对，就是如果熟悉一切都不是问题。但是对，就是学生面临的问题是他们不熟悉，咱们也不知道他到底哪块不熟悉。对。

Speaker 1 01:03:48 
对对对对对对对，这就是学生端的一个问题了，这也很难去考虑到，不应该很难说去计算出来。

Speaker 2 01:03:56 
对，就是很多老师他都没办法去考。对，可能只很有经验的老师才行。对。

Speaker 1 01:04:03 
对对对，是这样，我应该没有遗漏什么。你，你有什么补充吗？就是因为我觉得好像问的也差不多了。

Speaker 2 01:04:14 
嗯，那就查死我了，我还不知道，我已经忘了刚才问卷调查里面的内容了。

Speaker 1 01:04:22 
没关系，就因为我其实很关注于协作方式，就比如说你可能会有一些 interesting insights，就是比较有趣的点，然后就是我们没有考虑到的一些点，嗯。

Speaker 2 01:04:40 
应该，那我觉得你说。

Speaker 1 01:04:44 
没有就看你有没有什么补充的点。

Speaker 2 01:04:47 
我补充的点我主要是想的是那个assessment，就是因为如果说是后面要做这么一个系统，它是就它必须会涉及到评估，就测试评估，因为你不测试和评估你不知道。

Speaker 1 01:05:03 
你想说评估学生端是吗？还是评估。

Speaker 2 01:05:06 
对学生端，就是你不知道学生到底是属于什么样一个状态，就是如果学生在教室里，他就在你我的面前，我知道他的一举一动，我能看到他的表情，对对对对，但是 GPT 看不到。

Speaker 1 01:05:22 
但我就比如说什么摄像头监控学生状态，或者是我感觉都不太现实，这种通过这种方式。

Speaker 2 01:05:33 
对，现在主要问题在于模态的对齐，就是就包括那个 NLE 那边也在研究就怎么样把这个模态能够对齐，比如说我的那个EDA，我的 EDA 数据就是那个皮肤电数据，嗯，在某一个时间点，然后它有一个非常巨大的波动，然后这个是这个相当于说明我在这个时间点的时候经历了一个 physical arousal，就我的身体生理然后被激活了，我有可能是激动，我有可能是兴奋，我有可能是生气，一切都有可能对我的情绪是有起伏的。然后我再去看这个，比如说这个学生他在这个时间点到底在干什么？就是这两个就怎么说呢？这个就存在一个问题，就是到底是把重心放在哪个模态上？就是把重心放在就是以哪个模态的。的信息为中心，像这种情况我是以视觉的这个数据提供的信息为重点，就是我通过视觉去看这个学生可能站起来跳了一下或者是怎么样，就是他现在面临一个考试或者怎么，就是我可以通过视觉去看，但是这个是必须得去，因为我们要做这个模态之间的对齐，所以他必须得知道什么时间该看，什么模态是以哪个模态为准，他又知道这一点，这个是一个难点。

Speaker 1 01:07:07 
对，所以反而我们能观测到的最多是他，比如说他提问的这个提示词有没有什么变化，或者是就是只能从他的交互轨迹来看这个学生的状态。

Speaker 2 01:07:25 
对对对，就是大多数他只有一个数据来源，就是他的对，这个对话。

Speaker 1 01:07:34 
是这样，所以可能就很难去测量，因为心理状态不可能通过这个来表现。

Speaker 2 01:07:42 
对，然后他们就会，比如说就 nie 那边在做的，他们会加皮肤电，对吧？就是带一个小手表，他可以测那个皮肤电，然后他会给那个大脑上面带电极。嗯，测脑电，然后或者说是去看那个眼动，测这个就是去用那个眼动力，你去看这个眼睛注视在哪，然后去分析，但是很难对齐。就是这些东西你必须总结出来一套方法论，然后把这些不同的布局给他对齐了，然后才能形成一个非常合理的解释。

Speaker 1 01:08:17 
对，是，但说实话，假如我们只关注于这个学生有没有 critical thinking，就假设我就是去 assess 这一个点，我觉得可能就是会简单很多，因为我只关注于你的 critical thinking 有没有降低和提高，我不去关注于你的长期表现，也不去关注于你的精神状态，我觉得好像会好衡量一些，因为你的 critical thinking 可以通过，比如说你的 chat log，或者是你的output，或者是反正就是我觉得好像是能通过文本来量化个人感觉。

Speaker 2 01:08:54 
对，其实这 critical thinking 主要我感觉评估的话就评估两方面。对，对，就我们不说这个 critical thinking 它是对还是错，或者有价值或者没价值，我只看它有没有 critical thinking。对，这就很好量化。

Speaker 2 01:09:07 
对，就你看它的engagement，对，然后一个是一个方面，是它的 engagement 到底是高还是低？然后看它这个 engagement 它的输出的这个内容的在语义层面到底跟上一次输出的语义关系是什么？是扩大了还是更深入了呢？还是他如果缩小的话可能是一个不好的迹象？然后或者说是他一直在问同样一个问题，他也没有进行 creative thinking，但是如果说是他这个范围扩大了，或者是说是他的这个深度增加了，嗯，然后他的这个 engagement 还特别的频繁，嗯，那就说明他在 creative thinking，我是这么想。

Speaker 1 01:09:49 
的，对，因为我觉得这个是这么一回事，我也这么想的。就如果我一定要将脑电波这些就会变得很复杂，因为常就是很正常的一个问题，就是大家在用这个 GPT 的时候，我也不可能实时监测这些东西，就很现实的一个问题。

Speaker 2 01:10:06 
嗯，就是所以可以从文本上面，然后咱们就是这种情况就必须对学生进行限制，就是比如说必须得坐满多少轮的这个交互，对，然后每一次交互都必须得有一个完整的输入，就是必须有这种限制。

Speaker 1 01:10:24 
对，这个在实验的过程中肯定是能要求他们这么去做的，然后如果真的要强制性要求，就相当于说你这个提示词写得不够规范，就是可能就对话中让他去改他的提示词，只能这么说。

Speaker 2 01:10:39 
对对对，是的。

Speaker 1 01:10:41 
对，那访谈应该就先这样，然后我们可以往下去对一下那个 PPT 什么的，那我就先结束录音哈。诶，ok，好好，谢谢访谈。

Speaker 2 01:10:57 
好的，不客气。