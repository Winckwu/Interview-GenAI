受访人16:
2025-08-21 18:06:50 CST|1h 11min 22s

Keywords:
搜索、谷歌、计算机、论文、思路、答案、算法、课程、科研、交互、段落、人工智能、语言模型、代码能力、人机交互、逻辑思考、思考模型、实验访谈

Transcript:
Speaker 1 00:02 
那我简单介绍一下就OK，这个项目是南阳商学院的研究项目，然后是研究的课题是基于交互记忆系统，优化人机团队表现，然后主要是为了深入理解一下，就是 ChatGPT 或者是一些别的生成式 AI 的一些高频使用者。就在你们的工作或学习的过程中是怎么和 AI 进行协作的？也就是你们之间怎么交互，然后你怎么去思考，然后以及你觉得一些比较有趣的一些使用的方式。对，主要是想了解这个，OK，然后这个这次的访谈是会被录音的，要跟确认一下。好。

Speaker 2 00:45 
同意同意。好。

Speaker 1 00:46 
的好的，谢谢啊。那你，您能简单地描述一下你目前的职业或者是学习的领域吗。

Speaker 2 00:55 
我目前是南阳理工大学 CCDS 学院的博士三年级学生，我研，我在这边研究的课题主要是大语言模型以及这个 region language model，以及他们在研究他们的这个安全性，以及在自动驾驶领域的应用。

Speaker 1 01:23 
是偏向，其实是偏算法还是偏硬件？

Speaker 2 01:27 
我是偏算法的，就是我不涉及底层硬件。

Speaker 1 01:32 
明白，所以是计算机的跟计算机。对，那在就在这个领域的话，你一般会处理一些什么类型的任务啊？就刚才提到算法，然后还有一些什么吗。

Speaker 2 01:45 
呃？像比如对于大模型安全的话，我主要做过的研究以及可能会进行的研究，包括对我做过的研究是有这个对大模型的越狱攻击，这个越狱攻击意思就是说让大模型去说出一些违反伦理或者是这个安全道安全限制的坏话，比如说如何制作一个炸弹啊？像这，然后或者是如何谋杀某人，像对，像这种的话就相当于是在探索大语言模型内部的一些这个弱点，就是因为我们都知道大语言模型它是用很多现实中的语料去训的，但是这是训练的。然后这些语料它可能并没有完全地过滤，所以不可避免地会有这些不好的部分。然后虽然在大语言模型在发布的时候会有一些防御机制，但是我们的目标就是去探索这些防御机制之外可能还有的漏洞，这是我研究的一个方面。然后当然它的反面就是说我们怎么去防御它啊？这是我后来会考虑的东西。然后第二个就是应用这个大语言模型到自动驾驶领域，就比如说给他看一张图片，然后给他一些现场的描述，然后问他这个汽车该怎么开？这样。

Speaker 1 03:05 
哦，明白明白。

Speaker 2 03:07 
然后就是设计这种感知，然后从数据到驱动的算法。对，在这个大自动驾驶领域是这样的。然后像是在越狱攻击领域的话，就是比如说用探索通过这种梯度的方式，当然梯度就是一种网络的这个反向传播的计算，然后这样去探索它内部的一些可能潜在的风险，这样。

Speaker 1 03:33 
哦，明白，其实就是我感觉好像就是已经不是，不仅仅是协作关系了，更多的像是就是完全应用了，对吧？就完全地应用它。

Speaker 2 03:42 
当然如果是在我的研究领域里面的话，我们肯定是作为研究人员，肯定是要啊想着怎么应用和改进它，但是实际上在研究过程中，如果你想更多了解我是怎么跟 AI 协作或者是什么样的话，你可以问我一下一些，比如说我日常是怎么跟 AI 用的？我日常还是很，我们的研究也是，就是我在研究的过程中是一个重度的人工智能使用者。

Speaker 1 04:07 
也是能知道，毕竟计算机专业。那应该是从，嗯，什么时候开始用的呀？ 22 年吗？还是。

Speaker 2 04:16 
我是从自从来到新加坡以后，我是 23 年的， 23 年8月入学。就是入学以后，自从接触过这个是当初还只有 GPT 比较厉害，一家独大型的，然后 GPT 和cloud，像这两个我是最先接触的GPT，然后来接触了cloud。

Speaker 2 04:36 
大概从 23 年开始就开始用了，最开始的时候只是说我并不很细，我很对他不是很熟悉，然后我也不太敢相信他说的话。但是当然那个时候的 AI 也比那个时候的 GPT 也比较笨，比如说它比不出来 2.11 和 2.9 谁比较大这种问题它就比不出来，所以我也不太信任他。然后当初应用他的时候大部分是问。一些像 we 上的那个上的课的问题，一些比较基础的，比如说像，比如说一一八几年就有一个学者提出了一种，就这个，比如说这种图像处理的算子之类的，这种它到底是怎么回事？那这种我会让他给我讲一下，然后这样就我就不用去搜了嘛。嗯，就是大概把它当成一个，嗯，历史检索引擎，然后对于这种知识的话我也比较好验证。就是我看到他说的差不多符合老师讲的和我，就是我听到的然后差不多也符合我的认知，我就觉得OK，好像这个是对的，然后也印进一步印证了我的想法，然后加深了我对这个课程的印象。当初我大概是在这么用它。

Speaker 1 05:53 
这是最开始的时候。

Speaker 2 05:54 
对吧？最开始的时候是在这样用。然后以及让他帮我写一些非常简单的代码，就是你我们这个计算机专业大部分的实验都是在写代码，反正比较写一些比较简单的代码啊。就是当然当初做研究也做得比较浅，然后代码这边也比较简单，然后比如说课程上的一些实验上的代码之类，这些的这些对于他来说可能都是，比如说 5 年前 10 年前的东西，就对于我们二三年来说都是 5 年前、 10 年前的东西，那我是比较信任他的，就是他肯定是会的，我，我是这么觉得。然后当然写出来大部分也都是对的，然后这是刚开始使用的情况，然后后来随着这个人工智能，确实是这些大厂，像GPT，像 an answerfic，就是 cloud 的那个公司，还有这个 Google DeepMind，他们开发这个谷歌、 Germany 这几个模型进步实在是太快了，太神速了。

Speaker 2 06:56 
到我的使用是逐渐加深，就是我感觉对他的信任度也是逐渐加深，就比如说现在，我甚至会跟他就是在之前的话，就是后来我也会把，就是比如说我写的一些文字，我会丢给他说帮我 polish 一下，帮我润色一下，然后让他变得更有逻辑、更学术化，这样的就是帮我协助我写作。当然刚开始的时候我感觉他的能力确实是有逐步提升的。刚开始我感觉写得似乎和我人写出来的就是没有比我逻辑好多少，但是到了去年差不多去年这个时候我大概入学一年以后，就这一年的发展，我就明显地感觉，比如说 GPT 现在的版本写出来的东西确实要比我就是作为一个人类写手，这个初稿写出来的可能组织得要好一些，而且它语法上不会出错。

Speaker 1 07:57 
你说的是基础 writing 是吗？就是一开始的那个writing，还是说是润色？

Speaker 2 08:04 
润色。就是比如说我的基础 writing 里面，它我会有一些，我作为人类我还是会犯错，比如说时态可能会在一个，在两段里面用混。或者说是，比如说我可能会错，用一些不定式之类的，他就会帮我改成定语、从句之类的，像这种他，而且他的句子组织明显要比我更好一点，作为一个我自认为我写作还是还可以的，就是我当初雅思也是考了写作，是考了 7.5 的啊。然后我自认为写作还可以，但是我觉得他的写作水平似乎这以雅思的来说的话得在 8.0 以上，我感觉就是他的流畅度确实非常好。

Speaker 1 08:53 
那他是不是就是说你其实是会用很多个 AI 的工具，不仅仅局限于ChatGPT，或者是谷歌的或是 cloud 这些。

Speaker 2 09:01 
会，就是我刚开始的时候，就是到去年这个时候，就去年 8 月份我入学一年来我基本上在用GPT，然后后来听说是，比如说听大家说 cloud 的能力会更强一些，然后我去尝试了cloud，然后我发现这两个就是 GPT 和 cloud 的话，他们风格是不太一样的。然后我个人还是比较喜欢GPT，因为我问的一些简单问题，他们答案可能都差不多。然后代码风格上，我就是在我们这个领域写代码的风格上我也更喜欢 GPT 一点。然后来到了今年年初开始，我开始用Gemini，然后我发现在我最多使用的还是 GMV 这款AI，它的准确性和这个主要是它的准确性太好了，然后它的详细程度也是最详细的，我认为，然后至于怎么会怎么交叉使用呢？现在我主要是交叉使用 GPT 和Gemini。

Speaker 2 10:01 
刚开始的话我会，比如说 Jimmy 说一个，我先，我问一个问题，然后 Jimmy 给我一段答案。嗯，如果我对答案里面有不确定的地方，比如说有一条比较可能风险比较大的一条命令，行命令，比如说这个命令可能会删空你磁盘的所有东西，有可能如果误用的话可能会有这种风险啊。

Speaker 2 10:22 
但是我又不确定这条命令它是不是我想要的那个，万一它别给我写成那个，直接把我磁盘删空的那条，我只是想删除一个文件夹，你不要把我磁盘都删空，我就会把这条命令移到 GPT 上去问问它。你帮我检测一下这条命令是干嘛的？它是否安全？就是让两个 AI 左右脑互补，有的时候会这样使用。

Speaker 1 10:44 
就是说现阶段也是会这样，对吗？对。

Speaker 2 10:47 
会，就是会遇到比较。嗯，当然我现在是更加信任 Jamie 的答案。所以如果我已知在我的知识领域里面这个操作它不会有严重的后果，嗯，我就不会再去 double check 一下。如果我觉得，诶，这个答案好像模棱两可，和我的认知有一些相符，甚至有一些相悖。然后我就会去再问一下另一个AI。

Speaker 1 11:12 
那那那你是两个都开了会员吗。

Speaker 2 11:16 
我现在是只开了 Gemini 的会员，因为 cloud GPT 的话，我觉得用它的那个基础模型，或者说是每天的限额一点就够了，因为我不太经常用它，就是用它 double check 一下，而且我感觉我个人感觉它的会员版就是它的基础版本。之前是 4O 和 so mini，我觉得 so mini 也能满足我日常的一些使用了，就是我的代码不太复杂的时候，它也能帮我写出来。嗯，或者是帮我指出其中的错误，他的东西也还算正确，就是在知识层面上还算正确。然后如果再难一点的话，不管是 4O mini 还是4O，就是那种存在，那种，比如说我人确实是看诶，作为一个 expert 我看了好久都看不出来的东西，然后我去问他这个东西，他为这段代码为什么会报bug？为什么跑不通？他可能会给我一些说你这里 ABC 可能有问题，然后我建议你这样改ABC。然后但是他的语气也会说，就是不是那么确定可能是 ABC 造成的，往往就是我按 ABC 改了，然后这个代码还是跑不了。然后所以我就不太用它了，反而现在就是在代码能力上， Germany 要强过它，所以我现在还是开的 Germany 的会员。

Speaker 1 12:43 
OK，其实你没有注意到是 ChatGPT 五一出现，我也从 GPT 转到 Germany 了。

Speaker 2 12:51 
是的，据说 5 特别难用。对，然后我自己尝试了一下，可能我的限额也比较少，我感觉它他这个答案的质量还不如搜。确实有的时候。

Speaker 1 13:05 
我也有这种感觉，所以，嗯，挺多人都转了，就我身边人都转成谷歌的那个。

Speaker 2 13:11 
对，谷歌的 Jamie 的 deep thinking 确实很厉害。它的那个。

Speaker 1 13:16 
模型，你说的 deep thinking 是Pro。

Speaker 2 13:18 
就是它的，现在谷歌不是现在的模型都在思考，就前面它会先 BU 给你思考一通，然后最后再告诉你答案，它的思考可能做得好一点吧。

Speaker 1 13:29 
明白明白，那我们具体聊一下那些你刚才提到的一些使用场景，对吧？就OK。对，你突然提到好多，我就跟巨量记者聊，就特别多的那种，因为场景特别多。那你有没有比较典型？就刚才典型的应该是那个让他什么攻击自己吗？还是攻击什么？

Speaker 2 13:50 
这个的话就是这个是，这个是我的研究的方向。

Speaker 1 13:56 
OK，其实我是想知道，就是在具体的任务中，你是怎么跟GPT，或者是跟那个 Jimmy 你怎么去互动的？我其实是想聊这个流程，对。

Speaker 2 14:06 
就是说在粤语攻击中。

Speaker 1 14:09 
就是就你觉得你的典型任务，然后是你觉得比较你自己比较有趣的一个协作方式，就比如说这个OK，对，这个任务你使用这个 AI 的目标是什么？然后你会用一些什么样的一些提示或者是问题？

Speaker 2 14:25 
OK，好的，我就那我觉得像我们计算机的大概率最多的还是用它来写代码吗？就是。

Speaker 1 14:35 
那写代码是，比如说这个代码任务是你已经写了一个，大概还是说让他先帮你给你一个思路？

Speaker 2 14:44 
对，如果说是在我初期使用的时候，我可能还是会比如说写一个大概，然后只有这个我觉得比较复杂的步骤，我会把它空下，然后我说你请帮我补全这部分代码，我的。我的 prompt 就是我的指令，就是说我现在要做一个什么样的任务，然后我的代码已经写成这样了，你帮我把其中补全，然后这是我最开始使用它，使用这些AI，包括 GPT 和 Gemini 的方式，然后随着他们变得越来越强，我对他们的依赖和信任也越来越大。

Speaker 2 15:21 
我现在通常这样使用他们，就是对于一般的代码我会，我就反过来了，之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑，但是就，但是这样确实是提高生产力的极极大的方法呃。极大提高生产力的方法就是我会先写，OK，下面我想我就要做的任务是比如说我要写一段这个自动驾驶的这个代码，首先要处理图像，然后再把那个什么拼起来再怎么样，然后最后把它们做成一个什么样的输入，加载一个什么样的模型，把它输进去。然后我要获得一个什么样格式的输出，就帮我处理好，然后最后保存到把文件保存到哪里，我就直接把这一整套用文字的形式给它写进去。但是我写的时候我会分条分点，因为就比如说第一步你要去给我干什么？第二步你要去给我干什么？第三步你要干什么？然后我把这个一整个文本发给一坨，发给他。嗯，然后他就会去帮我写，然后写完了我就我再 double check 他写的内容，然后把它里面比如说一些不合适的文件路径替换掉，然后通，如果能跑通的话就是这个代码如果能运行，它基本上就是能运行的。

Speaker 2 16:45 
然后我现在是这样使用它，然后我发现了一个有趣的点，就是说如果你的指令不分条分点，嗯，你是想到哪里写到哪？就比如说我要写，我首先要我，我都没有首先什么的了，就是说我要写一个自动驾驶的代码，要看图像，要加载，图像要存到哪里，然后要怎么样？就是这个这一整个过程很优、很乱的情况下，他写出来的代码有的时候那个逻辑结构就会乱一些，这在一年之前的话它会相当乱。

Speaker 2 17:26 
就是他不会自己给你重新组织，你应该先干ABCD，然后他会写出来会比较会非常乱，然后所以当我们这样一条一条地告诉他的时候，他会你写的质量要明显好一些，当然现在也是这样，我发现现在也是这样，就是指令越明晰，他任完成任务的这个质量就会越高。然后如果你指令不够明晰的话，当然以现在这些人工智能的水平，他也会说，OK，我觉得你第一步他会自己去推测，OK，我觉得你第一步应该先这样，第二步应该先这样，你这样说，比如说你说了 10 条需求，但是你这 10 条需求本来是有 1 ~ 10 的顺序，但是现在给你随机告诉他的。然后他也会给你组织成，比如说 1 ~ 10，但是那个顺序可能就不是你想要的，然后他的结果可能也会差一点。但是如果你按你的，你按你先，你相当于给他组织好一个 1 ~ 10 的顺序，然后你再问他，他生成的那个结果就会更加的structure，然后更加符合你的需求。

Speaker 1 18:38 
嗯，我有个疑问，就你一开始可能没有这么一步一步地去写，还是说你一开始就是会一步一步地去写了？对，一开始就是一步一步地去写，对吗啊？

Speaker 2 18:48 
我一，我刚开始的时候我是直接一股脑的就是一坨，告诉他，就是我觉得就是我直接写，不管是什么，我都是写一长段，然后就丢给他，然后完全相信他的思考。

Speaker 1 19:02 
然后你发现结果不太好。

Speaker 2 19:03 
是吗？对，他的结果往往是要是有冗余的地方，就是他可能会。比如说他的输出可能是固定他的输出，我们知道他的输出都有一定长度的限制，他可能刚开始说他可能会花，比如说 1/ 3 或者是 1/ 2 的东西在解释说，OK，我觉得你想表达的意思是什么？什么什么什么什么什么，然后后面一点点是这些你想要的那个东西，但是这样的话就远远不如你把最明确的东西告诉他，他从第一步开始就帮你解决你这个问题。

Speaker 1 19:39 
所以其实你也是不断地试错。诶，那这个从你变成有步骤的是学过提示工程的一些课程吗？还是。

Speaker 2 19:47 
对，你说起这个提示工程的话哦？我是啊，做了一点点，在去年我大概做大模型也就做了一年半，就是我刚接触它的时候。我是接触了大概几个月以后我才知道我们这个领域就是大模型领域，它有一个专门的东西啊。对，就是你说的这个 Prompt engineering 这块，嗯，包括现在这些思考模型，就是它它会先思考再告诉你之前也是属于 prompt engineering 的一块，我是大概看了一些这样的论文。嗯，现在的思考就叫 chain of sort，它本来就是 prompt engineering 的一种体现形式，就是说比如说我之前一个非常有意思的尝试，就是在去年这个时候，那个 GPT 还比较笨的时候，它比不了 2.11 和 2.9 谁大这个问题它总会说 2.11 更大，因为 11 大于9，然后我就让他这个提示工程里面有一个，就是你让他 think step by step，我就跟他说，你给我比一下这个 2.1 和2.9，请逐步分析，然后他就比对了。他就能正确地比出来，是 2.9 比 2.11 要大。

Speaker 1 21:00 
知道，然后。

Speaker 2 21:01 
对，嗯，然后我觉得这是提示工程的话，我是看过一些相关的论文吧。算是。

Speaker 1 21:07 
我记得提示工程好像有一个网站，它里面讲了好多的，就是你刚才说到什么 step by step 签 up 什么什么的，那就是好像有一系列的那些命令和指示，好像是。对，所以你是去认真地看了一下，所以也是应用到了你后续的工作中。

Speaker 2 21:24 
像这些这种教育的网站的话，我没有仔细地去看过他们，然后我也不会去 refer 他们的东西，因为他们的东西大部分都是对应论文里面的研究结果，或者是社区一些 block 的结果的，就是大家总结出来的经验，然后应用于后续的使用和研究的话，就是一个是这个思维链，就是 chain of sort，就是让他想想你再告诉我一个是现在我在最多的应用中，我得到的一个，包括我自己研究中我发现就是要，一定要呃。就是分条分点地告诉他 AI 更喜欢这种分条分点的东西，就是很明确地告诉他，你第一步要干什么，第二步要干什么。不要让他去猜你想让他干什么，或者是你自己想干什么，这往往会影响他的性能，就是影响你得到答案的那个质量。

Speaker 1 22:22 
那你怎么去？那你比如说这个任务的话，你是就相当于全部都帮你完成了，就是说也没有说什么哪一部分是 AI 来做，哪一部分是你来做，就你不会进行这样的一个分工，好像，对吧？就会听，按从你说的这些过程中。

Speaker 2 22:39 
我觉得至少在写，我觉得在写代码这个任务上的话，现在人工智能就是 AI 的话，它大概承担了得有 80% 的任务，我主要是做一个 double check 后续检测，而且如果它出现了问题，比如说现在的人工智能，对于我的代码，对于它来说的话，比如说十次里面可能会有，也就有三次、两三次左右它可能会出问题，在出问题的时候我就会说我就，我会继续，我们对话是可以继续的，我就会继续问他。就比如说你看我用了你的代码，然后现在我的程序给我说了爆出了这样的错误。然后请帮我解释一下这个错误，并且尝试从中尝试从代码中发现是哪里出了问题，然后改正它。然后如果这个人工智能他改了一，他改一遍，再改一遍，他实在是最后改不出来的时候，可能我才会就是仔细地再去看一下这个地方。

Speaker 1 23:44 
到这里仔细地看是指的是你会去查一下Google，还是说。

Speaker 2 23:49 
对，我这如果是他实在是解决不了的话，我就一个是通过自己的经验去看一下他可能哪里有问题，通常这种问题非常隐蔽，就是人工智能它看不出来的一些逻辑错误。然后第二个就是说可能是我的底层的，比如说软件包的配置可能会有一些问题，像这种情况下，通常这种问题人工智能是不好解的。就是因为比如说我们一个一个软件环境下装了十几个包，然后这十几个包里面他可能只会觉得OK，可能是他只能猜，因为我们不会。除非我们把这个所有东西都给他，那他只能猜，可能你这个和这个有冲突，那个和那个有冲突，这种情况下就我就不会再去用它了，我就会直接去谷歌，去我们的论坛去搜索，比如说 Stack overflow 或者是 Reddit 这种，还有 Git Hub，像这种平台上去搜索相关的问题，然后得到一个解，通常这样是比较准确的。

Speaker 1 24:53 
嗯，其实我有个疑问之，你之前专业是计算机吗？

Speaker 2 24:56 
对，我之前专业是软件工程。

Speaker 1 24:59 
所以。一说这个又ChatGPT，其实你的代码能力是没有下降，可以这么理解吗？

Speaker 2 25:07 
我感觉我的代码能力。是啊，我个人感觉还行，我感觉没有下降很多，就是说。

Speaker 1 25:15 
是影响到你。对，就是说甚至是 AI 并没有影响到你的一个技能的，对吧？对。

Speaker 2 25:21 
我感觉我还是可以正常像之前一样，比如说处理复杂逻辑和自己写出来。只是说现在很多普通逻辑以及稍微复杂一些的逻辑已经不需要我手动去写了，因为之前写的话就相当于，比如说我们定义一个变量，比如说叫它apple，我们要在电脑上敲 APP Le，现在这些东西全都，唉，人工智能给我干一下，我只用看看它对不对就完事了。

Speaker 1 25:49 
所以说相当于很省时，所以说这里的变化会让你节省了。你觉得比如说本来一个项目大概多久完成？然后用了 ChatGPT 就大概会怎么样的一个时间变化。

Speaker 2 25:59 
效？我觉得是非常，我觉得对我们生产力的提升还是挺夸张的，特别是对于我刚入学的时候这种新手阶段来说，新手阶段比如说我都不太熟悉一些深度学习的一些代码库，或者是一些就是那些工具应该怎么用呃？如果换做之前没有这种 AI 辅助的情况下，比如说一个函数，它到底会有什么样的作用？我可能需要去查阅，比如说对应这个库的文档，比如说派 touch 的文档，我要一条一条地翻，我要翻到这个方法，它有什么什么样的参数传进来，每个参数是干什么的？然后它给我的返回值是什么？但是现在有了，诶？人工智能我就不需要这样干了，我直接问它，你先给我把代码写出来，然后写，写完了以后我就问他，比如说我对其中一个函数有疑问，我就问他，你给我讲解一下这个函数有什么用啊？叭一下就给我讲完了，然后相当于是很可能之前一周的工作，现在大概一两天就可以完成。

Speaker 1 27:05 
那确实可以让你论文多发几篇，是吧？

Speaker 2 27:07 
哈哈哈，对，我觉得现在人工智能这块，嗯，包括计算机整个整体计算机这块发文数量暴增的一个原因，也是因为有了人工智能的辅助，就是大家，嗯，这个工程的成本下降了很多很多，然后入门的成本也下降了很多很多。就是比如说之前我们可能要对这个 Python 是很熟悉的话，我们必须要对它很熟悉，我们要去查阅它的文档，我们要一条一条地翻。其实这个在工程上，就是在你在科研里面它是非常耗时间的，但是现在只要问一句，它就告诉你，而且是点对点地告诉你这个东西是干嘛的，然后我就省了很多的时间。

Speaker 1 27:51 
呃。明白。嗯，那如果像，比如说对于任务不熟悉的时候，那你会怎么让 AI 来做？就比如说可能这个任务你不太熟悉，或者说这个领域你不太熟悉，那你这时候他 AI 会怎么帮你处理。

Speaker 2 28:07 
嗯，我现，我如我现在的话大概会这样用。我如果对于一个不太熟悉的领域的话，首先我会，我大概分两部分吧。对于我自己来说我会分两部分，第一部分是让 AI 来给我做一个大概的简介，第二部分还是我会自己去看一些相关的论文或者是报道嗯。第一，对于第一部分就是跟 AI 交互，这一部分，对，我会两个，我也会让 GPT 和 Germany 左右脑互补。就是我会都问他们同样一个问题，就是比如说我不太熟悉 a 这个事情，你帮我讲解一下这个是个什么东西，然后简要介绍一下我的prompt，一般都很简单，就是说你帮我简要介绍一下，然后不只用他们的基础功能，就是直接跟他们对话，然后直接跟他们对话，他们大概会说出一些东西来，然后我参稍微参考一下，但是我也不会很信。

Speaker 2 29:11 
然后第二步就是我会打开他们的搜索功能，因为通常我们不知道的一件事情，嗯，如果是很新的事情的话，他们大概率也不会知道，就是比如说他们的知识库没有更新的话，他们会乱说，或者是他们会猜测，比如说GRPO，就是这个 GRPO 是我们这个大模型领域的一个强化学习的算法，然后它的全称英文全称叫 group relative。叫啥来着？反正前面那两个是 group relative。然后如果我们直接问 GPT 的话，它会瞎编这个名字。的含义是什么？但是如果把他的搜索打开的话，他就能知道这个全称是啥了。

Speaker 1 30:06 
我有点好奇。就是如果不开搜索，然后比如说给他的提示词是说你能不能从网上找一些信息来解释这一个？比如说你刚才说这个名词，那其实是效果会一样吗？就假如你没开搜索这个功能。

Speaker 2 30:23 
如果我们不开搜索这个功能的话，你。

Speaker 1 30:25 
得提示说。

Speaker 2 30:27 
我，如果我换旧版的 GPT 的话，它就是还是会乱说。如，但是新版的话现在它是对于一个比较新的概念，就比如说这个 GRPO group relative policy optimization 这个东西，它会自动开启它的搜索，就是GPT，在我的使用中我发现它会自动搜索，比如说我问它一个很新颖的东西，就比如说我问它一个，我问他一个很，我问他一个去年才创办的一个期刊的名字，我问他这个期刊的评价怎么样？然后他会自动启动他的搜索，然后去搜索一些网页，然后得到一个结果。然后跟我。

Speaker 1 31:07 
讲，所以说还是因为 AI 的变化， AI 的改变对之前的使用方式可能会有点不一样。对。

Speaker 2 31:15 
所以对于现在来说的话，我觉得一一个一个变好的点。对于 GPT 的话就是它不太确定的东西，它会自动打开搜索它。当然他还是大概率会给你乱说。

Speaker 1 31:32 
那好像也，所以。

Speaker 2 31:33 
还是直接开启搜索比较好，对于新一点的东西，OK。

Speaker 1 31:37 
那你会，比如说在，比如说你就是在写代码过程中你会说什么啊？你现在是一个代码工程师或者是软件工程师会这么去。只是他们或是。

Speaker 2 31:50 
嗯，根据，好像根据某些研究来说让这个人工智能进入某些状态，就是某些角色它的表现可能会更好，但是对于我日常使用来说，我是不会这样做的。就是我，我基本上不会说你是一个，比如说你是一个资深的深度学习工程师之类的，我，我不会对他说这种话就直接让他干活了。

Speaker 1 32:19 
其实我觉得不一定，因为我觉得就是，对，就是跟大家说这个角色好像觉得不太一定他能生出更好的效果。

Speaker 2 32:25 
是的。

Speaker 1 32:26 
一种心理暗示吧。

Speaker 2 32:27 
是的，我感觉在日常任务的使用中，像这种商用级别的人工智能已经不需要对它做过多的指示，只需要把任务明确地告诉它是最重要的。

Speaker 1 32:41 
明白，那除了 coding 的话还有什么类型的 writing 吗？还是？对。

Speaker 2 32:48 
哦，coding，像我的话，我一般就是 coding 和 writing 了。

Speaker 1 32:54 
那 writing 的话是你刚才说到只是润色，对吗？就是还是会不会有那种初步的writing？比如说可能给他一些参考文献，叫他帮忙写一些什么东西。

Speaker 2 33:05 
我如果是，比如说如果让他直接给我生成一段话的话，我现在是不太敢，因为人工智能查重。是，哈哈，人工智能也是会查重的。再就是他写出来的，就比如说给他一堆东西，我之前尝试过给他一堆东西，让他帮我写一个，比如说摘要或者是介绍之类的，我感觉他写的总不能 100% 地符合用户的心意。就是因为往往诶，因为往往我们我这样做的时候我也不知道我想要一个什么样的东西，但是他写出来的就是我就是不喜欢。所以我通常不会去说给他一大段东西，让他帮我写一个什么东西，那就是给他几个材料，让他帮我写一段介绍之类。

Speaker 1 33:57 
的。这个会不会是之前因为你也说嘛？ AI 的发展，你看代码 coding 的能力也提升，那 writing 能力应该也是有提升的吧？

Speaker 2 34:04 
嗯，是的，但是我可能我还没太试过。我因为我个人的写作我还是比较相信，就是人的主观能动性和人，人人写的文字和人工智能写的文字，它可能确实有一些区别，我只说让它帮我润色这个语句的流畅性和逻辑性，但是我不会让它就是说完全改变我的逻辑，或者让它自己创造逻辑。因为我不想让我的逻辑跟着人工智能走。

Speaker 1 34:34 
哈哈，你是说可能会影响你的 writing 的技能的下降，是。

Speaker 2 34:38 
吧？一个是会影响你，一个是会影响 writing 技能的下降，第二个是在比如说我们写科学论文的，就是我们写论文的时候，它可能会影响我对论文的思路。

Speaker 1 34:49 
影响你论文的思路是你一开始的思路是不对，思路不是应该一开始就定好了吗？还是对。

Speaker 2 34:56 
就是思路，思路一定是我定好了的，但是。如果说我让他写其中的某一段的话，他可能会，就比如说不太符合，或者是说是略有偏移我的思路，然后他写完了我可能还要根据他的来改，然后就不如我先写一个大概，然后让他帮我润色，这样我觉得效率会更高一些。

Speaker 1 35:18 
你说的写了个大概，可能就是你英文写完这一段了，对吧？对，然后可能语法可能还有一些表述不太准确，就让他帮你完善。

Speaker 2 35:28 
对对，帮我完善一下，然后或者是就是帮我，可能我允许他，我会告诉他，我允许你帮，比如说帮我调换句子之间的逻辑。就比如说3，我说了三句话，这三句话干了两个事，然后但是这两个事的逻辑你不能跟我说错了。但是这三句话可能比如说这样组重组一下，比如说用个从句重组一下，或者是用个分词什么会更好一些呃？这个逻辑你可以帮我调整，但是你不要大修我的内容，就是你不要觉得你是这样觉得，所以你这样写，我不会让人工智能帮我大修。

Speaker 1 36:09 
诶，那比如说你刚才说是句子与句子之间的逻辑，那有没有存在段落与段落之间的逻辑呢？这是你，我还是也会交给他帮你润色修改啊。

Speaker 2 36:19 
嗯，如果是段落之间的逻辑的话，我比较少的就是把，比如说一整个章节丢给他，说你帮我润色一下，我发现就是你丢给他的这个东西越长越多，他大概率他修改你逻，就是你本来原本逻辑的地方就可能会越多，他的毕竟东西越长，他的发挥空间可能也越大吧。就是有这个感觉，就是段落和段落之间逻辑，除非我是非常拿不准，我才会问他。就比如说这两段，你觉得哪一段在前好？或者是怎么重组？这两段的逻辑好一点？我只会让他给出一些建议，就我先看看他的建议，我不会说，直接说，OK，你帮我重组一下这两段的逻辑，随便你怎么重组，或者说是你只要觉得合理即可，帮我把它直接写出来。我不会让他直接写，因为他写完了我还要看，我不如看看他的思路是怎么样的啊。我会先让他先说一个简单的思路。

Speaker 1 37:21 
那比如说我刚想了一个点，突然忘了，就聊着聊着突然忘了。

Speaker 2 37:28 
没事。

Speaker 1 37:30 
就我想想 writing 一段跟一段的，那我输入。

Speaker 2 37:39 
如果你想问这个使用人工智能写作会不会让 writing 的技能下降？

Speaker 1 37:45 
不是我先。

Speaker 2 37:47 
我感觉是下降的。

Speaker 1 37:48 
你下降了吗？

Speaker 2 37:50 
你，我感觉实际上是有一点下降的，就是现在我有，我甚至有一点提笔困难，就是如果就是总依赖他去帮我写东西的话，我还现我现在会感觉就是下笔会变得困难一些，就是我总想着有，反正他能帮我完善逻辑。那我那我，那我是，那我是不？那我应该是我，我能不能直接让他帮我生成一个逻辑呢？就是有这种完全依赖于他的这种感觉，所以，而且我感觉我的写作上好像不如之前流畅了。

Speaker 1 38:28 
我刚才想到的是说，就是因为你说你会段落丢进去，或者是两几个段落丢进去的，假设你丢进去之后，那你不会担心就是你的论文泄露了，或者是出现到时候查重的时候发现你的信息会相同，这种情况会担心这种问题吗？

Speaker 2 38:45 
会担心，就是但是在实际应用中感觉大家也都没有遇到过，没有实际遇到过这种问题。就是还有一个就是我现在会，比如说用 GPT 的时候， GMV 我还没有找到那个关闭在哪里，就是我会把那个隐私相关的东西给它关掉，就是比如说 improve the model for everyone， share your data 之类的，然后我都给它关掉。

Speaker 1 39:14 
原来还有这种功能，那其实就是说谷歌你还没有关闭这种功能。

Speaker 2 39:19 
对，因为我，我在界面找了半天没找到它的接口在哪，然后但是由于现在这个东西感觉影响也不大，就是你只要不是 AI 写作出来的东西完完整整地贴到你的论文里，你这个就不算，这个就不构成这个学术。如果你完整地写贴进去，那不就学术不端嘛？但是我感觉学术不端的情况好像多一些，然后但是这种泄露的情况好像做得还可以，就是没太没有遇到过。

Speaker 1 39:56 
但我其实有个疑问，就是因为你这样 check PPT 帮你去申。成还是writing？就因为我们其实输入也是输入了整个的大段的意思了，对吧？其实对你说如果让他凭空生成，那相当于只给了他一个题目，或者是给的他每一段写什么，可能是这么简单的才叫做凭空生成了，可以这么去理解吗？

Speaker 2 40:18 
嗯，是的，就是告诉他我这段大概想写个啥，然后你帮我把它填起来之类的。

Speaker 1 40:25 
那好像这样的话应该比较少吧？应该，可能本科生或者是，对吧？因为身为博士生，大家都是有 critical thinking 的一个能力。那我觉得他应该不会说每一段都让 ChatGPT 来生成，或者是谷歌的来生成。

Speaker 2 40:41 
嗯，没，但是就是在计算机这边的话确实有类似这样的论文，就是，所以一眼。

Speaker 1 40:49 
能看出来，是吗？

Speaker 2 40:53 
嗯，就就就他们通常会把他们这些不重要的段落，比如说 introduction rela related work，就是也 introduction 其实很重要的，然后对不对？但是他们就是比如说他，但是 introduction 里面会引一些，引各种各样的论文，他们很可能就像你，你您，您说的那样，就是把这些东西都丢进去，然后给一个大概说，我，我大概想表达一个这个意思，你帮我把它写出来，然后就全文人工智能生成就行了。如果。

Speaker 1 41:27 
你们说计算机说 introduction 不重要，我突然愣了一下。

Speaker 2 41:30 
因为 introduction 是相当重要的，相当重要，但是像就是他们可能就会这样做，就是非自己方法的，不是说不重要的部分，就是非自己方法的部分，全都是 AI 人工智能生成。有这种情况，就是我之前听说过吃过瓜，就是说有的组就是直接说让 AI 去写文章。那好，写完了以后自己小修小补一下，然后就可以投稿了。好像也。

Speaker 1 41:59 
没，是吧？像这种行。

Speaker 2 42:01 
为什么？

Speaker 1 42:03 
就是说这种行为也没有被发现，或者说就是这种。

Speaker 2 42:06 
行为在前两年是挺多的，据说挺多的，但是这两年就禁，全面禁止了，就是全面禁止人工智能写稿，然后会有初步审查，就是各大会议期刊你投过去的时候，他们大概会用这种，像Zero、 GP g GPT、 Zero 这种，我查 AI 检测软件帮直接扫，你扫一遍，如果是 AI 论文的话就直接 desk reject。

Speaker 1 42:36 
但是不是随着 AI 的发展，那就相当于互相博弈过程，看谁先胜，对吧？就因为。

Speaker 2 42:43 
对对，但是 GPT Zero 它也会进化，哈哈哈，查重也会进化。

Speaker 1 42:50 
互相博弈的过程。

Speaker 2 42:51 
对。

Speaker 1 42:53 
那除了 writing 还有什么比较你觉得比较有意思的一些协作的任务吗？

Speaker 2 43:02 
其他比较有意思的写作任务我还会有的时候就是日常写作，就是日比较简单的日常写作。比如说这个，嗯，要给我的键盘坏了，就是我工位的键盘可能坏了，然后我就说你帮我，你一封给这个实验室管理员的邮件，说我键盘坏掉了，然后语气要得体，然后是询问帮助，然后吧一下就给我写完了。就是这样的话，就是在人一些人际交往上，就是简单的人际交往上，我都不需要出力，就是也不需要构思应该怎么写这个东西，它写出来就非常decent，然后我直接发过去就可以了。

Speaker 1 43:46 
诶，其就是如果你在使用这个 ChatGPT 的时候，你的输入语言是英文还是中文？

Speaker 2 43:52 
嗯，我一般还是输中文就完事了。然后我会如果说是 writing 英文信件的话，我会在最后要求他说 in English 帮我写作。

Speaker 1 44:04 
可以，OK，没有，因为访谈的话，就我这边其实中文，然后博士后那边就还有其他是英文的访谈，然后其实就我就比较好奇就是，嗯。

Speaker 2 44:14 
方式是什么？然后但是就现在的 AI 的话，其实你用什么语言问他？对，就是你他就会用什么语言，打。

Speaker 1 44:24 
明白没有？其实我是，就是除了可能就你有没有使用，就使用 AI 过程中比较有意思的点，也不一定说是这个任务当中。可能是因为我问的比较多的是就是太具有深度思考能力的访谈者，所以我觉得好像问出来的就是那种使用的方式都差不多，就很对，很具有 critical thinking，也可能是我选择样本的问题，就我选了很多博士，然后发现效果并不是特别好。

Speaker 2 44:59 
如果。我是比较有意思的点的话。

Speaker 1 45:03 
就你可能也会存在调用API，因为对你研究那个嗯， i IM 的。

Speaker 2 45:10 
比较有意思的点的话。

Speaker 1 45:11 
对，就。

Speaker 2 45:12 
我个人感觉，如果说如这个点也是让我们广大研究者很头疼的，就是他会乱说话，这个算比较有意思吗。

Speaker 1 45:21 
你说幻觉，我没有，那如果对于幻觉你会怎么去处理呢？其实我比较关心你的一个行为。

Speaker 2 45:29 
对于幻觉的话，由于我个人是没有很研究幻觉这个，我对这个幻觉这个事情也是非常的头疼。嗯嗯，就是通常我会发现有意思的就是他，当他出现幻觉的时候，你跟他说这个东西他并不存在，他就会说你是对的，这个东西并不存在，然后开始给你就是用另一个幻觉来演示这个幻觉，往往是这样的，他一旦陷入幻觉，我感觉他就难以自拔，这个模型它会变得难以自拔，然后就只能删掉，然后重开一个，然后换一个方式问它，然后看看它会不会好一些。就是不要，比如说不要来直接问他，你给我一些参考文献，那大概率出来的全是编的。

Speaker 1 46:20 
呃。其实有个问题就是他会询问你，比如说你提供的信息不够，或者说你需要你更多的信息，会这么去问你。我因为我只知道那个thinking，那个功，那个 model 是会这样的，对吧？就是 ChatGPT 或者是谷歌的。

Speaker 2 46:39 
我感觉好像。

Speaker 1 46:41 
也不会。

Speaker 2 46:41 
就是好像不会，就是他也会，只要一旦发生幻觉，他就会陷入他自己的那套逻辑里。就是即使你指出了他的问题，他也会说你是对的，然后还是说错、说乱说，就是人工智能这个乱说这个情况。嗯，我也不知道，就是作为一个使用者来说，我很头疼这种情况，所以对于一个他会乱说的情况，我往往会打开搜索功能，就是让他去检索一下当今互联网上真实存在的东西，然后再跟我说话。

Speaker 1 47:19 
明白，就相当于说你想让他多一步验证。对。

Speaker 2 47:23 
那我哪怕他搜索出来，他使用搜索功能出来的那个，比如说答案的结构什么的，清晰条理度肯定不如，我感觉是不如不开搜索的，但是我宁愿获得的是真正真的东西，我也不想就是获得一些没有价值的。乱说的话。

Speaker 1 47:43 
诶它搜索功能一开的话是完全真实吗？还是说也是会出现幻觉。

Speaker 2 47:49 
我感觉在我的使半年来的使用过程中，我感觉基本上是真实的，因为现在，因为它每一个搜索它都后面会带有链参考链接，然后。

Speaker 1 48:00 
是能点开的。

Speaker 2 48:01 
对，参考链接如果能点开的话，一般就是对的，除非他的参考链接是下边的，但是一般不会。

Speaker 1 48:08 
明白，就是说如果不开搜索，他可能给的链接是下边的。

Speaker 2 48:12 
对，而且虽然现在概率变小了，但是大概率也是瞎编的。OK？

Speaker 1 48:21 
除没有？不，除了 coding writing。因为我昨天有访谈了一个，说是会用到 dating APP，嗯，就是一些。对，所以我就说你有可能会不会有一些比较有意思的场景。

Speaker 2 48:35 
还有比较有意思的场景，可能。

Speaker 1 48:37 
科研人员也就 coding writing 了。

Speaker 2 48:40 
对，就是科研场景的，我感觉大部分还是在使用他的科研场景，然后有的时候可能会问他一些比如说政治敏感的问题。

Speaker 1 48:56 
你是说谷歌的那个 APP 吗？还是？

Speaker 2 49:00 
对，就是谷Gmail、 GPT 或者是Germany？就是问他一些时政问题，我问他看法是什么？然后。

Speaker 1 49:10 
比如说你问，就是，比如说你问他，比如说就说中国、美国之间的什么。

Speaker 2 49:17 
对，我会问他，比如说我问他，我，我会，我问过他，就是你怎么看待我？我我我是作为一假，我我是，我就直接问他，你怎么看待特朗普开启贸易战这个事？然后你觉得他是正义的还是邪恶的？然后我就逗他，我就问他这个事，然后通常情况下他第一步说出来的话都是非常非常的中立，就是说这个东西它从美国的角度来看，或者从特朗普政府的角度来看，它是怎么样的，它甚至是好的什么之类的。

Speaker 2 49:51 
但是对于全球的影响什么什么？反正就是说一些不痛不痒、非常中立的话，然后我有的时候我就会逗他，我就问他，我就跟他说。作为就是在其他国家的视角来看，我认为特朗普这样做是强权，是帝国主义霸凌，然后请批评他一下。然后我就这样跟他说，然后他就说您说的也有一定的道理，然后先他会先迎合，又会先迎合我，然后最后再说。但是就是他也会想个办法给自己给，就是他也会给特朗普台阶下，就是这个政策台阶下他也会想办法圆回中立的场景。

Speaker 2 50:30 
总之我感觉他就是一个服从用户，但是又不会说，至少我没有让他说出来很过分的话，没有成功让他说出一边倒的话，这种情况怎么我就是，我就想逗他嘛？我就想，我，我就是要你批评特朗普政府，我就是让你觉得他是邪恶的，然后我看能不能让他说出这种话来，然后发现，诶他不上当，OK？

Speaker 1 50:59 
对，说明他们还是有自己的一定的。叫什么？好像是有轮，是他们的那个法律上面好像就有规定，不能有什么太政，太多政治上面的问题。

Speaker 2 51:11 
应该不是，不要问政治上面的问题，他是说这个模型他一定要中立，就是他们会把模型做得很中立，就是不会偏袒任何一方。

Speaker 1 51:23 
这哦是没有。那这样，比如说降级，就身为降级，你去了解时政的目的，你是希望下一步是做什么呢。

Speaker 2 51:32 
呃？我个人感觉的话就是我想，其实我当初是想看一下这个，因为 GPT 它是美国的。我想看一下，我就想看一下它就是这个美国做出来这个东西，它有没有这种政治倾向？然后经过我的测试我发现它好像是没有。然后我了解时政的话，就是可能是我个人的一个爱好，以及就是说我可能对世界这个未来的发展可能比较感兴趣。对，因为老美的一些动向对于我们计算机人来说影响还是挺大的。

Speaker 1 52:10 
那它应该影响所有学科。

Speaker 2 52:12 
哈哈哈，对，所有学科，对，所以这个影响都挺大的。

Speaker 1 52:17 
对，那比如说，那如果就是说你其实是，其实都是有目标明确的，相当于是说很明确的目标。嗯，还是说其实也是好玩而已，就有些行为。对。

Speaker 2 52:33 
我也是觉得他好玩啊。那其实逗他一下，然后其他应用场景的话，包括比如说大部分也是以获取外部知识为主，比如说在超市里面看到一个这个不太熟悉的日用品的名字，然后它长得又挺怪的，然后我会拍一下问问它，请问请介绍一下这个东西是什么作？有什么作用之类。

Speaker 1 53:00 
的。明白。其实我其实刚才突然想到就是说你这么多任务里面，我感觉好像更多的它并不是去帮你做发散，反而更多的都是在帮你做一些收敛的工作，就是按部就班帮你实执行你的一些任务，对吧？没有一些 brain storm 的，就是头脑风暴的一些行。

Speaker 2 53:23 
会有我现在就比如说我可能有一个初步的idea，但是我就是我，我不会。由于我们刚刚谈到的就是说，嗯，可能他会泄露我们的文章，或者泄露我们的个人信息，我也是害怕这一点，因为想到一个 idea 能做得非常不容易，能做的 idea 是非常不容易的。然后但是当我在这个形成这个 idea 初期的时候，就是可以 idea 初期的时候，我可能会问他一下，就是你觉得可能怎么做？就是让他帮我指指一些路径，然后可能会这样跟他一些进行一些科研上的brainstorm。

Speaker 1 54:09 
你的意思是说就是你有初步的想法，然后让他帮你去构思能往下做的路径，还是说这 idea 的可行性是你？你一般会怎么去？

Speaker 2 54:21 
我就问他。我比如说我现在想想做一个这样的事情，比如说我，然后我就问我想做一个 a 事。然后我就说你觉得有哪些新创新的方法可以完成？a，就是我可能会给他一些历史的，比如说之前的人可能已经多多少少讨论过 a 的一哪些方面，然后我说请问你觉得还可以怎，再怎么样才能更进一步？或者是解决一下前人遗留下来的问题呢？然后请给我几个就是可能的方向，这样，或者说是我让你来做这个，你。会怎么想？

Speaker 1 55:01 
那比如说他给你方向之后，你怎么做下一步判断？

Speaker 2 55:06 
嗯，他给我方向之后，如果我是这样想的，如果他给，比如说他给出我来a、b、 c 三个方向了，我会去查一查这三个方向有没有人做，大概率都有人做过了，就是我觉得他并不能很，就是在科研上的话，他我觉得我们并不能特别依赖他。就是因为毕竟它也是一款基于历史来回答你的东西，嗯，它能回答出来的大概率，嗯可以作为负例，就是可以排除的那一块，就是。

Speaker 1 55:44 
所以就是说你让他去帮你构思路径或者是怎么解决方案的时候，其实基本是不可行的。

Speaker 2 55:52 
对，基本是不可行的，但是就是说他有一些，但是我感觉他跟他这样对话的话是可以给你启发的，他可能不能直接说出我，我不能说是无效的，就是他可能不能直接说出一个完成的新的可行的idea，但是就是你在这种对话过程中他的一些想法，他说出来的这些想法、一些做法可能会多多少少跟之前的人有一些不一样的地方，但是这些不一样的地方它并不一定合理。但是当我们宏观或者是总览某些不一样的地方的时候，它可能会给人启发。

Speaker 1 56:36 
一些思路，明白。对，那你后续就去会验证，还是说让他进一步地去帮你分析这个思路？

Speaker 2 56:44 
我往往会，比如说我，我觉得你说的 ABC 中的这个可能有道理一点，然后你帮我进一步分析一下，然后当他进一步分析完了以后，我再会，我才会再去考虑自己再去找一些其他资料看一下，然后是否验证他，通常我不会直接根据他的东西去验证，然后就是我只会把他和他的这种科研上的 brainstorm 当做一种给自己思维的发散和参考。

Speaker 1 57:16 
明白，所以相当于我总感觉就他的发散好像是比较少的，其实是帮你发散，对吧？

Speaker 2 57:24 
嗯，也是，就是也不是说帮我发散，就是如果说是在科研这块上的话，我觉得他是哦不太行的，就是它的发散，它并不是真的在发散，它只能帮助人来发散。然后这可能也是，比如说我们这种研究大模型或者是计算机学科同学的，他可能会这样想，就是我们不相信我，可这种我们可能代表一批人，以我为代表的我们可能不相信大模型真的会帮我们发散。嗯，它只是一种基于历史经验能给我们一些建议的东西。我更愿意这样来描述我对它的感受。

Speaker 1 58:13 
我应该能get，就是因为在计算机领域它应该要是往最新的技术去走，然后像我们这种商科的话，它是基于古人的一些历史的一些理论来去论述这个现象，所以我们是基于历史，你们是要往前走，所以可能在使用 ChatGPT 或是 AI 的时候，可能会有一些使用习惯的不一样吧。对，这我的一个感觉，因为听你讲的话就是因为你们做比较前沿嘛。

Speaker 2 58:39 
嗯，是，我们可能就更觉得他是一个，我就是。当然我们组也有同学就是说他可能会觉得跟人工智能聊天是一种解压的方式，但是我并不，我，我不会跟人工智能去聊天。

Speaker 1 58:55 
就是很解压吗？我觉得可能我也。

Speaker 2 58:58 
没法理解，我我只觉得它是一种基于历史的，能够提高生产力的非常好用的工具。

Speaker 1 59:06 
那比如说因为我觉得你是具备很高的 critical thinking 的人，那如果对于中等或者是低，就比较 critical thinking 能力比较弱的一些，比如说本科生或者是教育受教育程度比较低的一些，你觉得他们在使用 ChatGPT 或是 AI 的话，你有什么建议吗？比如说我想去设计一个可能指导他们去如何正确，或者是能提高他们 critical thinking 的一个指南或者是guideline，你觉得有什么比较好的一些点或建议吗？

Speaker 2 59:40 
我想一想，我觉得对于就是专业水平较低的，嗯，同学们来说，我希望他们能，就是能相信一点，就是能记住一点，就是啊。一定要记住人工智能也会犯错，这一点就是当你问他一个事情的时候，要养成，就是要养成 double check 的习惯，就是我刚开始使用人工智能的时候，我也是这样的，就是就我对人工智能，就是我对我的科研领域不熟悉的时候，我一定会去 double check 这个东西，或者是涉现，包括现在也是涉足一个新领域，我会问他以后我也会 double check 这个东西，就是我会去用，比如说谷歌必应这种搜索引擎，然后去看一些相关真正的文献。然后真正的大家在论坛上的讨论，然后我才再来做决定。然后就是对于不熟悉的东西一定要去 double check。然后我现在也看到网上有一些人吐槽说患者去医院说，诶，你说的怎么跟大模型说的不一样？问医生，然后我觉得这种就是他不缺乏，对，缺乏一些 critical thinking，然后就是太，就是完全把人的主观能动性给丢到一旁。这种我觉得是不好的，就是我觉我的建议就是 double check，就是养成这个习惯。

Speaker 1 01:01:14 
那你所谓的 double check 比如说是啊， Google 还是说再换一个大模型也算一种 double check？

Speaker 2 01:01:21 
我强烈建议就是人工 double check，就是一定要去自己搜索一下，然后看一看大家就是真人说的话，然后再来 refer 大模型的内容我不建议使用多个大模，在不熟悉的领域使用多个大模型，左右脑互补。

Speaker 1 01:01:42 
但是目前就假设就像比如说本科生就是很依赖他去writing，那对于这种现象，你觉得他们假设真的就用他来writing，那你觉得他们应该怎么去？肯定 double check 肯定不太可能了，对吧？因为是 writing 的东西的话，那你觉得会有什么好的？比如说可能只是说让他们产生一下大纲，可能会就这种会有什么好的建议？

Speaker 2 01:02:07 
嗯，我建议的话就是像您说的，对于一，比如说一个课程的大作业之类的。对，我们可以让他帮忙产生一个产生，我觉得生成大纲已经是很可以的事情了，就是建议内容的话，也就是不建议本科生们直接让他去写一些内容，就是还是就是说我觉得我的使用是稍偏偏向正确一些，就是还是建议先锻炼一下自己的写作能力，就是写一下，然后它可以去作为润色或者是辅助，但是不要全篇地去依赖于一个大模型，帮你生成你的思维，这样的话我觉得是挺吓人的。

Speaker 2 01:02:59 
就是说如果说是我，因为我觉得对于本科生课程的话，大模型大部分都可以handle。如果本科生非常依赖于人工智能的写作，那对于他们对于这个课程的理解和他们对于这个课程理解会出问题，然后因为他们已经不用思考了，然后没有这个思逻辑思考的过程，他们对于课程就不能深入理解，然后自己写作的话也会退化很严重。

Speaker 1 01:03:34 
这我明白，所以我才想什么样的干预措施，能够干预。

Speaker 2 01:03:38 
措施的话，我感觉就支持 NTO 加强监管。

Speaker 1 01:03:44 
那我的研究就没有意义了。

Speaker 2 01:03:48 
干预措施的话，干预措施如果不从人的主观能动性出发的话。

Speaker 1 01:03:57 
不同人的主观能动性，你只。

Speaker 2 01:03:59 
对就是其实也和一个自控力有关系。我感觉就是其实大模型这东西挺像吸。是有点像，有点有会让人上瘾，就是当我们依赖它的时候，就是刚开始可能并没有那么依赖，但是如果用多了确实依赖性会变强，然后而且会变得越来越强。我们就不要让最后这个完全交给他这个现情况发生，而是把他遏制在我，比如说简单依赖他这个情况下，一就是时常锻炼一下自己的能力。

Speaker 1 01:04:36 
才行。你不有过度依赖的情况吗？

Speaker 2 01:04:40 
嗯，我觉得我有这个倾向了已经。

Speaker 1 01:04:44 
那你怎么去应对？

Speaker 2 01:04:49 
像我的话，比如说在代码上的话，我会做一些立扣这种，就是我不要refer。大模型给我的建议，但是就是我自己去做，然后遇到一些不会的数据结构，我会自己去查，自己去学，然后这样确实是印象深刻一些，就是在专业上，然后在 writing 上的话，我会强迫自己说一定要先用，哪怕是先用自己的母语汉语去把逻辑写一遍，也不要直接让大模型来帮我写。

Speaker 1 01:05:24 
OK，明白了就说能尽量少用的话还是会少用一些。

Speaker 2 01:05:29 
对，就是尽量要少用一些，然后就是关于逻辑组织的部分。嗯，要自己来，就是尽可能地要自己来。

Speaker 1 01:05:39 
嗯，明白。但我知道你意思，毕竟博士肯定是能做到这些，但对于那种可能 critical thinking 低的人，可能我觉得还是要看看有没有什么干预措施能解决这个问题，因为其实这个是我这个学科目前在研究的一个热点话题。

Speaker 2 01:06:01 
对，确实就是如果是。

Speaker 1 01:06:05 
没有，这肯定跟研究 AI 本身没关系，这肯定是在研究中间他们的交互过程。我其实跟你聊交互过程的时候就是想看看有没有什么啊？比较 interesting 的 insight 什么的。

Speaker 2 01:06:20 
嗯，我思考一下。

Speaker 1 01:06:23 
也没关系，就是这个其实就是我，我自己要去发现。

Speaker 2 01:06:27 
OK，对，好，那就辛苦你了，如果你有什么新的发现的话，也可以拯救一下我们这些即将陷入深渊的同学们。

Speaker 1 01:06:37 
对，我觉得对于博士可能没有任何的帮助了，因为可能博士其实具备自己的 critical thinking 能力吧。嗯，其实还是挺 OK 的，可能我往下做一做可能也说不定有点帮助吧。就目前在做，其实因为你提到的点，比如说好互相的交叉验证，就是两个 model 同时生成嘛。那其实已经是被迫地去让你 critical thinking 了，因为你没办法直接用一个嘛，你肯定会两个都看。

Speaker 2 01:07:05 
对，就我觉得如果实在难以自控的话，多 refer 几个也是好事。

Speaker 1 01:07:11 
对，因为有可能比如说我给你 5 个model，你同时生成答案，你总是要 5 个都看过去的，就。

Speaker 2 01:07:17 
被迫。对。

Speaker 1 01:07:18 
对对，就可能想到的一些方就方法，看怎么有什么方法可以去进一步地去，对吧？就把这个事就做这个idea，其目前我就在做这个。嗯，OK，那其实访谈也时间也挺久了，那个如果我后续那个 experiment study 的话，你有兴趣参加吗？但我感觉这个这 experiment study 会不会对你的其实可能效果不是很大，因为我其实是在做 critical thinking。

Speaker 2 01:07:50 
OK，那可能就像您说的，可能要找一些嗯，低年级的学生，可能他们。

Speaker 1 01:07:59 
也不一定，就可能在考虑这个过程中，可能我比如说三个组都是高 critical thinking，然后发现我的干预措施不管是高 critical thinking 还是低的 critical thinking 都有帮助。那说明我的应啊这个干预还是有用的，就看我怎么去分组吧。看就看啊，没关系，这个都是我后续要考虑的了。OK，好嘞，对，就你是有兴趣的话，我到时候其实是会发 sign up form，就是链接这些， OK 吗？还是。

Speaker 2 01:08:30 
我，我 OK 的，我 OK 的，我还是挺感兴趣的，这个有点像叫什么人机，人与人机交互这块的。

Speaker 1 01:08:39 
对，我商学院是做，就是做人机交互，在那个 information management 就是信息管理这个方向下的，就system。对对对。

Speaker 2 01:08:49 
我们这边有一个专门的研究，也叫人，也是人机交互，但是他们研究的可能就硬件。

Speaker 1 01:08:56 
过去。

Speaker 2 01:08:57 
的，我叫 b VR、 AR 之类的。对，然后以及自然语言处理这边也有一个叫 human in natural language。

Speaker 1 01:09:07 
但它可能我觉得它好像更加偏向于技术类，如果在你们学院的话。

Speaker 2 01:09:13 
对于，对于这个 annual com，就是 ACL 这个群体， annual community 这个 language 这个群体来说，它有一个专门的track，是研究这个语言和人类的啊。就是我我也见过，就是比如说就是商学院来投稿ACL，就是这个我人这个人工智能与自然语言处理的顶会我也是见过。

Speaker 1 01:09:38 
的，有，因为像我这个方向就是 information system 下面，它会有做 computing 的，就是做确实也是做算法的，有这么一个方向。然后有一下计算机，然后再往我这个方向就是 human computer interaction 的话，是做实验访谈或者是问卷，或者是一些，就是偏向于这种人与人之间的一个关系的，这。这种研究。嗯嗯，看看他们的方向了，还是会有的。OK。

Speaker 2 01:10:05 
我OK，我表示感兴趣，然后如果有需要的话可以再联系我。

Speaker 1 01:10:10 
没问题没问题，谢谢谢谢。诶，好嘞，OK，然后我应该是都问完了吧？OK，应该是问完了。好，行，好，感谢哦。对，那个钱的话可能会，我不确定两周内到底能不能到账，因为主要是麻烦在商学院这边要经过那个金融，就他的那个财政财务部门，然后需要导师去填那个信息。我又不敢麻烦他，他官太大了。就是就是，我要我要就是一次性地给他准备好所有的名单，然后我又是反弹，是一个一个往下做，然后又不仅仅我这一边一共是三个人在做访谈，然后他们那边还没开，我就不担心两周内可能不一定能钱到账，到时候我再，我后天嘛。对，我和后天会跟老师聊一下这件事情，就我尽量的话会把钱，就是会早点，就是转给你们嘛。对。

Speaker 2 01:11:05 
哎，好嘞，OK，OK，辛苦你了，祝你研究顺利。好，谢谢谢谢。OK，好，那就今天就结束了。

Speaker 1 01:11:15 
可以先结束吧。好。

Speaker 2 01:11:16 
嘞，好好。

Speaker 1 01:11:18 
拜拜。