
\begin{table}[htbp]
\centering
\caption{现代机器学习模型性能对比}
\label{tab:modern-model-comparison}
\begin{tabular}{lcccccc}
\toprule
\textbf{模型} & \textbf{发布年份} & \textbf{测试准确率} & \textbf{5折CV} & \textbf{F召回率} & \textbf{F精确率} & \textbf{F1} \\
\midrule
\textbf{Random Forest} & 2001 & 95.5% & 95.5±1.4% & 100.0% & 100.0% & 100.0% \\
CatBoost & 2017 & 94.7% & 94.7±0.9% & 99.4% & 98.7% & 99.0% \\
XGBoost & 2014 & 94.4% & 94.4±0.5% & 99.4% & 100.0% & 99.7% \\
Voting Ensemble & - & 94.2% & 94.2±2.4% & 99.4% & 99.4% & 99.4% \\
SVM (RBF, C=10) & 1995 & 94.2% & 94.2±1.6% & 99.4% & 99.4% & 99.4% \\
LightGBM & 2017 & 94.2% & 94.2±1.4% & 100.0% & 100.0% & 100.0% \\
Gradient Boosting & 2001 & 93.4% & 93.4±2.3% & 100.0% & 100.0% & 100.0% \\
Stacking Ensemble & 2017 & 92.8% & 92.8±1.0% & 100.0% & 100.0% & 100.0% \\
Decision Tree & 1986 & 91.0% & 91.0±2.1% & 100.0% & 100.0% & 100.0% \\
MLP Neural Network & 2012* & 90.2% & 90.2±3.3% & 99.4% & 89.6% & 94.2% \\
KNN & 1967 & 88.9% & 88.9±3.1% & 98.7% & 96.2% & 97.5% \\
AdaBoost & 1997 & 88.1% & 88.1±1.9% & 96.8% & 94.4% & 95.6% \\
Logistic Regression & 1958 & 87.8% & 87.8±2.3% & 94.9% & 96.7% & 95.8% \\
Naive Bayes & 1960s & 83.3% & 83.3±2.0% & 92.3% & 96.0% & 94.1% \\

\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item 注：*MLP年份指现代深度学习框架成熟年份；所有模型使用class\_weight='balanced'处理类别不平衡
\item 数据来源：本文研究 (N=378)
\end{tablenotes}
\end{table}
