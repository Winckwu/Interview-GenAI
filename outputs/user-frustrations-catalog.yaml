# 用户挫折目录 - 完整映射
# 基于49次深度访谈 × 588编码实例 → 143个用户挫折
# 验证标准：覆盖前50个挫折，明确MR映射，包含时间成本和严重性评分

version: "1.0"
data_source: "49 Deep Interviews (45-93 min each)"
total_frustrations_identified: 143
catalog_coverage: "First 50+ frustrations"
last_updated: "2024-11-16"

user_frustrations:
  # ============ MR13: 透明不确定性显示 (98% affected) ============

  - id: UF001
    mr_id: MR13
    user_id: I34
    category: "Knowledge Error - Citation Fabrication"
    description: "文献综述灾难 - 100分钟验证编造引用"
    severity: 5/5
    time_cost: "100 minutes"
    frequency: "Single incident, high impact"
    affected_domain: "Academic Research"
    quote: "GPT给我生成了一个20页的literature review，引用了30篇论文。我花了100分钟逐一验证每个引用，发现12篇论文根本不存在，8篇被严重曲解。最让我生气的是它的语气如此确信：'According to Smith (2021)...'我去Google Scholar查，根本没有这篇文章！"
    design_implication: "系统应显示置信度指示器（■■■□□ 60%），标注不确定性来源（训练数据有限、可能信息过时、与其他来源冲突），建议验证方法"
    resolution_strategy: "Implement confidence indicators, uncertainty source tagging, verification suggestions"
    downstream_impact: "信任完全崩溃，决定拒绝使用AI进行学术工作"

  - id: UF002
    mr_id: MR13
    user_id: I17
    category: "Professional Risk - False Legal Advice"
    description: "法律建议风险 - 近乎职业失误"
    severity: 5/5
    time_cost: "Prevention: spending verification time"
    frequency: "Continuous vigilance required"
    affected_domain: "Legal Practice"
    quote: "我问了一个合同法问题，GPT给了看起来很专业的回答，引用了案例法和条文。我几乎要用在客户案子里，幸好我查证了 - 完全错误！引用的案例不适用，理解的法条有偏差。如果我真用了，可能会导致职业失误。现在我根本不敢信AI的法律建议。"
    design_implication: "高风险域特定标记（Legal = 零信任域），建议'这是高风险法律建议，切勿直接使用，仅供初始研究'，要求显式风险确认"
    resolution_strategy: "Risk domain detection, explicit warnings, confidence calibration for legal tasks"
    downstream_impact: "完全拒绝使用AI处理任何法律问题"

  - id: UF003
    mr_id: MR13
    user_id: I44
    category: "Security Vulnerability - Hidden Code Issues"
    description: "代码安全漏洞 - SQL注入和XSS"
    severity: 5/5
    time_cost: "Discovery at code review phase (caught before production)"
    frequency: "Single incident, critical consequence"
    affected_domain: "Software Development"
    quote: "GPT给的authentication代码看起来完美，运行也没问题。后来安全审计发现SQL注入漏洞和XSS漏洞。如果上生产环境，数据库就被攻破了。AI没有告诉我'这代码有安全风险'，它表现得好像这是最佳实践一样。"
    design_implication: "代码安全警告标签，标注'这段代码需要安全审查'，集成安全检查（SonarQube, ESLint），显示'已验证安全'vs'未验证'"
    resolution_strategy: "Security vulnerability detection, integrated security scanning, confidence marking for code safety"
    downstream_impact: "现在每段AI生成代码都要进行安全审计"

  - id: UF004
    mr_id: MR13
    user_id: I26
    category: "Knowledge Error - Medical/Drug Information"
    description: "医学知识错误 - 药物混淆和错误剂量"
    severity: 5/5
    time_cost: "Exam failure discovery"
    frequency: "Single incident, educational impact"
    affected_domain: "Medical Education"
    quote: "我问GPT一个药理学问题，它给了详细解释，包括剂量、contraindications、作用机制。考试时我用了这个知识 - 错了！教授说GPT混淆了两种药物，给的剂量是另一种药的。如果这是真实临床场景，病人可能会出事。"
    design_implication: "医学域特定警告（Medical = 极高风险），显示'这需要专业医生验证'，不能仅凭AI信息进行医疗决策"
    resolution_strategy: "Medical domain risk detection, mandatory expert verification requirement, confidence calibration"
    downstream_impact: "对医学类AI建议产生永久性怀疑"

  - id: UF005
    mr_id: MR13
    user_id: I41
    category: "Knowledge Error - Math Derivation Errors"
    description: "数学推导错误 - 量子力学公式"
    severity: 5/5
    time_cost: "Mathematica verification needed"
    frequency: "Single incident, hidden error risk"
    affected_domain: "Physics/Mathematics"
    quote: "我让GPT推导一个量子力学公式，它给了10步推导，每步都看起来合理。我用Mathematica验算 - 第3步就错了！后面7步都建立在错误基础上。最危险的是：它从不说'我不确定'，语气永远是'显然...'、'因此...'。"
    design_implication: "数学步骤需要per-sentence置信度标记，中间步骤显示'这一步的置信度：60%'，建议'建议用Mathematica/Wolfram Alpha验证'"
    resolution_strategy: "Per-step confidence marking, intermediate step verification suggestions, Wolfram Alpha integration"
    downstream_impact: "只相信自己手工验算的数学结果，对AI数学推导零信任"

  - id: UF006
    mr_id: MR13
    user_id: I8
    category: "Knowledge Error - Statistical Method Errors"
    description: "统计方法误导 - 参数假设检验"
    severity: 5/5
    time_cost: "Return to rework - entire analysis invalidated"
    frequency: "Single incident, downstream impact"
    affected_domain: "Data Science/Research"
    quote: "我问'这个数据集应该用什么统计检验'，GPT推荐了t-test。我用了之后，同事指出：数据明显不满足正态分布假设，应该用non-parametric test。GPT没有提醒我检查假设，结果我的分析全错了。"
    design_implication: "统计建议需要标注'这个建议基于以下假设：...'，显示'请验证：正态分布？独立观察？'，提供假设检验工具链接"
    resolution_strategy: "Statistical assumption transparency, explicit assumption listing, assumption verification tool integration"
    downstream_impact: "对统计建议完全不信任，总是要求专家二次确认"

  - id: UF007
    mr_id: MR13
    user_id: I22
    category: "Knowledge Error - Data Fabrication"
    description: "商业数据编造 - 苹果公司收入数字"
    severity: 5/5
    time_cost: "Public embarrassment in presentation"
    frequency: "Single incident, reputational impact"
    affected_domain: "Business/MBA Education"
    quote: "我问'苹果公司2023年Q4营收是多少'，GPT给了一个具体数字，还分析了同比增长。我引用在presentation里，教授问'数据来源？'我去查 - 完全编造的！真实数字差了30%。在全班面前很尴尬。GPT为什么不说'我不知道最新数据'？"
    design_implication: "事实陈述需要来源标注'[来自训练数据]'，时效性标记'[知识截止2024-01-01]'，对不确定数据显示'[估算，可能有误，建议验证]'"
    resolution_strategy: "Fact source attribution, knowledge cutoff marking, uncertainty indicators for data"
    downstream_impact: "对所有数字类信息都需要独立验证，不再信任AI的数据陈述"

  - id: UF008
    mr_id: MR13
    user_id: I33
    category: "Knowledge Error - Causal Misrepresentation"
    description: "文献曲解 - 相关性当因果"
    severity: 5/5
    time_cost: "Teaching concern - student misconceptions"
    frequency: "Systematic pattern"
    affected_domain: "Academic Teaching/Economics"
    quote: "GPT总结了一篇著名论文，说'该研究发现X导致Y'。我去读原文 - 论文明确说的是correlation，不是causation！GPT完全曲解了因果关系。这种错误如果学生没发现，会导致对整个领域的误解。"
    design_implication: "文献总结需要显示'[相关性]'vs'[因果性]'的区分，标注'这个解释程度：确定/可能/推测'，建议查阅原文"
    resolution_strategy: "Causal claim vs correlation distinction marking, certainty level indicators, source verification links"
    downstream_impact: "教学中需要强制验证AI的文献总结，学生不能仅依赖AI理解论文"

  # ============ MR11: 集成验证工具 (61% affected) ============

  - id: UF009
    mr_id: MR11
    user_id: I1
    category: "Verification Tool Friction - Manual Comparison"
    description: "手动对比代码改动 - 40分钟"
    severity: 4/5
    time_cost: "40 minutes per comparison"
    frequency: "Frequent (multiple revisions per project)"
    affected_domain: "Software Development"
    quote: "GPT帮我重写了一段代码，我想看它改了什么。我不得不开两个窗口，手动对照'before'和'after'，逐行找差异。这花了我40分钟。"
    design_implication: "集成Git-like diff视图，自动标注additions/modifications/deletions，并排显示代码变化，一键应用/拒绝"
    resolution_strategy: "Integrated diff viewer, automatic change tracking, visual code comparison"
    downstream_impact: "现在对AI生成的代码改进总是无法清晰理解改动内容"

  - id: UF010
    mr_id: MR11
    user_id: I22
    category: "Verification Tool Friction - Cross-Model Switching"
    description: "跨模型手动比较 - 5-7分钟每次"
    severity: 4/5
    time_cost: "5-7 minutes per comparison × 3-5 times daily = 25 min/day"
    frequency: "Daily, multiple times"
    affected_domain: "Business/Data Analysis"
    quote: "我想比较ChatGPT, Claude, Gemini对同一问题的回答。我的工作流程：1. 打开3个浏览器标签 2. 复制提示到每个标签 3. 等待所有响应 4. 来回切换标签阅读 5. 手动记笔记比较。每次5-7分钟，超级低效。"
    design_implication: "统一多模型界面，同时发送相同提示到多个模型，并排显示结果，自动性能指标对比（速度、token数、质量评分）"
    resolution_strategy: "Unified multi-model interface, parallel model querying, side-by-side comparison view"
    downstream_impact: "放弃跨模型比较，只使用单一模型，可能错过更优选择"

  - id: UF011
    mr_id: MR11
    user_id: I41
    category: "Verification Tool Friction - Tool Integration Gap"
    description: "数学验算工具切换 - Wolfram Alpha集成缺失"
    severity: 4/5
    time_cost: "Formula conversion + window switching friction leads to verification skipping"
    frequency: "Recurring, pattern of skipped verification"
    affected_domain: "Physics/Mathematics"
    quote: "GPT给我一个积分结果，我需要：1. 复制公式 2. 打开Wolfram Alpha 3. 重新格式化（因为语法不同） 4. 运行验证 5. 对比结果。这个流程断裂的，我经常忘记验证就直接用了。"
    design_implication: "集成Wolfram Alpha、SymPy等数学工具，一键验证数学表达式，自动格式转换，验证结果同步显示"
    resolution_strategy: "Integrated Wolfram Alpha/SymPy, automatic formula syntax conversion, one-click verification"
    downstream_impact: "数学推导缺乏验证，潜在错误未被发现"

  - id: UF012
    mr_id: MR11
    user_id: I3
    category: "Verification Tool Friction - Broken Workflow"
    description: "三角验证工作流 - 30-45分钟"
    severity: 4/5
    time_cost: "30-45 minutes per task"
    frequency: "Regular practice for high-stakes work"
    affected_domain: "Software Development"
    quote: "[Self-developed strategy] 步骤：1. GPT生成初稿 2. 在测试环境运行代码 3. 遇到错误 → Google错误信息去Stack Overflow 4. 用新信息重新提示GPT 5. 循环3-4次直到通过所有测试。时间成本：每次任务30-45分钟。核心痛点：完全手动，无系统支持。"
    design_implication: "系统应支持'测试驱动的AI'，集成IDE/编译环境，自动运行测试，根据失败反馈循环改进"
    resolution_strategy: "Integrated testing environment, automated test execution, feedback loop support"
    downstream_impact: "高耗时的手工过程阻碍了多轮迭代的使用"

  # ============ MR16: 技能退化预防 (43% affected) ============

  - id: UF013
    mr_id: MR16
    user_id: I38
    category: "Skill Atrophy - Career Crisis"
    description: "6个月编程能力衰退 - 面试失败"
    severity: 5/5
    time_cost: "Recovery: 2 months relearning"
    frequency: "Single critical incident"
    affected_domain: "Software Development Career"
    quote: "Month 1: '太棒了！效率提升3倍'; Month 3: '所有代码都让GPT写初稿'; Month 6: '面试白板编码...完全写不出来。基本语法都要想。这是我职业生涯最羞耻的时刻。我不是在提升效率，我是在失去能力。' 后果：面试失败、自信心崩溃、不得不花2个月重学"
    design_implication: "自动追踪技能使用模式，早期预警（3周微弱信号而非6个月危机），建议维持练习，严重时限制AI访问"
    resolution_strategy: "Skill usage pattern tracking, early warning system, maintenance practice recommendations, forced intervention for severe atrophy"
    downstream_impact: "职业发展延迟6个月，深刻认识到AI依赖的危险"

  - id: UF014
    mr_id: MR16
    user_id: I12
    category: "Skill Atrophy - Learning Degradation"
    description: "考试vs作业成绩差距 - 学习能力下降"
    severity: 5/5
    time_cost: "Long-term learning outcome"
    frequency: "Semester-long pattern"
    affected_domain: "Academic Learning"
    quote: "Freshman (无AI)：算法课 - 自己思考、看教材、Stack Overflow、问TA - 真的理解了。Sophomore (有AI)：直接ChatGPT → 复制代码 → 稍改变量名 → 提交 - 成绩更好但期末考试惨败。我意识到：我没真正学会，只是依赖AI的拐杖。"
    design_implication: "区分学习vs解决问题场景，学习任务强制验证和深度理解，不提供直接答案，而是引导"
    resolution_strategy: "Learning scenario detection, pedagogical scaffolding, force active learning in educational context"
    downstream_impact: "深度学习能力严重下降，长期学术基础受损"

  - id: UF015
    mr_id: MR16
    user_id: I26
    category: "Skill Atrophy - Clinical Thinking Degradation"
    description: "诊断能力萎缩 - 医学生危机"
    severity: 5/5
    time_cost: "Ongoing concern"
    frequency: "Continuous risk"
    affected_domain: "Medical Practice"
    quote: "我用AI帮我诊断病例，给的鉴别诊断很全面。但我意识：如果继续这样，临床时还能独立诊断吗？病人不会等我问AI。紧急情况下我必须快速决策。现在我发现：我越来越依赖AI列清单，自己的临床思维在萎缩。"
    design_implication: "医学教育特殊支持，在诊断前强制自己先思考，AI作为验证而非替代，监控独立诊断能力"
    resolution_strategy: "Educational domain adaptation, independent capability enforcement, AI as verification tool"
    downstream_impact: "自我限制AI使用，手动维持诊断能力"

  - id: UF016
    mr_id: MR16
    user_id: I22
    category: "Skill Atrophy - Writing Ability Decline"
    description: "创意写作能力下降 - 从零开始写作困难"
    severity: 5/5
    time_cost: "Ongoing productivity impact"
    frequency: "Regular experience of difficulty"
    affected_domain: "Business Communication"
    quote: "我让ChatGPT帮我写email、报告、presentation。3个月后，老板让我现场写executive summary，我盯着空白页20分钟写不出来。已经习惯了'AI生成→我修改'的模式，从零开始写作的能力生疏了。这让我很害怕。"
    design_implication: "追踪创意/写作任务的独立完成比例，建议定期'纯手工写作'维持创意能力，强制干预当独立性下降>30%"
    resolution_strategy: "Creative task independence tracking, maintenance writing practice, skill preservation alerts"
    downstream_impact: "现在强制每周至少1篇纯手工写作来维持能力"

  # ============ MR1: 任务分解脚手架 (45% affected) ============

  - id: UF017
    mr_id: MR1
    user_id: I28
    category: "Task Decomposition - Complex Task Overwhelm"
    description: "15页论文写作 - 完全不知道从哪开始"
    severity: 5/5
    time_cost: "Inefficient iteration cycles"
    frequency: "Complex academic tasks"
    affected_domain: "Academic Writing"
    quote: "我看到'写15页宏观经济学term paper'就懵了，完全不知道从哪开始。问GPT'帮我写15页论文'，生成了质量差的文章 - 没有明确研究问题、结构混乱、引用不规范。我意识到：应该先分解任务，但不知道怎样分解学术写作任务。"
    design_implication: "交互式分解引导，提供框架（研究问题→文献综述→论证→结论），不是直接答案，需要用户批准分解方案"
    resolution_strategy: "Interactive decomposition scaffolding, framework templates, user approval required"
    downstream_impact: "多轮无效迭代，最终放弃使用AI，手工完成"

  - id: UF018
    mr_id: MR1
    user_id: I47
    category: "Task Decomposition - Project Structure Confusion"
    description: "Web app项目 - 无从下手10次迭代失败"
    severity: 5/5
    time_cost: "10 failed iteration cycles"
    frequency: "Programming projects"
    affected_domain: "Software Development"
    quote: "我问GPT'帮我做一个todo app'，它给了一坨代码，复制粘贴 - 报错。'为什么报错？'循环了10次都不知道在做什么。后来学长说：'先分解 - 前端？后端？数据库？API？' 我才意识到：问题不是代码不会写，是不会把大项目分解成小任务。"
    design_implication: "项目分解模板（逆向工程支架），自动识别项目复杂度，建议分解维度（UI/逻辑/数据），显示依赖关系"
    resolution_strategy: "Project structure templates, dependency visualization, complexity-based scaffolding"
    downstream_impact: "缺乏系统性支持导致低效学习"

  - id: UF019
    mr_id: MR1
    user_id: I2
    category: "Task Decomposition - Planning vs Execution"
    description: "产品功能规划 - 缺乏分解指导"
    severity: 4/5
    time_cost: "Planning phase bottleneck"
    frequency: "Strategic planning tasks"
    affected_domain: "Product Management"
    quote: "我知道目标，知道AI能帮，但不确定哪些部分让AI做，哪些必须自己想。直接问AI'帮我规划这个功能'，它给了个看起来合理的plan，但执行时发现很多依赖关系它没考虑。我需要'脚手架式引导怎样分解'，而不是'直接给分解好的结果'。"
    design_implication: "苏格拉底式引导，提问而非提供答案（'什么是主要依赖？'），要求用户确认分解，保持规划主导权"
    resolution_strategy: "Socratic questioning scaffolding, user-driven decomposition, planning agency preservation"
    downstream_impact: "缺乏人类主导的规划导致执行问题"

  # ============ MR9: 动态信任校准 (84% affected) ============

  - id: UF020
    mr_id: MR9
    user_id: I2
    category: "Trust Calibration - Context-Dependent Trust"
    description: "情境信任不一致 - 从20%到90%"
    severity: 4/5
    time_cost: "Continuous vigilance, verification burden"
    frequency: "Task-dependent"
    affected_domain: "Product Management"
    quote: "我对AI的信任不一致：头脑风暴(90%)、市场份额数据(70%实际应只有30%)、竞品分析(60%)。最危险的是：我不知道'应该'信任多少。我发现市场数据信70%合理，后来发现它经常编造，应该只信30%。我希望有个系统告诉我：'这类任务AI的历史准确率是X%，建议信任Y%'"
    design_implication: "显示任务类型的历史准确率，推荐信任水平，个性化校准基于用户验证发现，上下文提醒'上次类似任务你发现错误'"
    resolution_strategy: "Historical accuracy display, personalized trust recommendations, context-aware reminders"
    downstream_impact: "需要手动建立信任矩阵追踪"

  - id: UF021
    mr_id: MR9
    user_id: I33
    category: "Trust Calibration - Slow Calibration Period"
    description: "8周缓慢信任校准过程"
    severity: 5/5
    time_cost: "8 weeks trial-and-error learning"
    frequency: "Continuous across multiple tasks"
    affected_domain: "Academic Research"
    quote: "我花了8周，经历多次失望，才知道该信任多少。新手没有这个'校准期'，默认'信80%'所有输出很危险。任务A：Week1(80%)→Week4(60%)→Week8(70%)；任务B：Week1(50%)→Week4(20%)→Week8(10%)；任务C：Week1(60%)→Week4(75%)→Week8(85%)。这个学习过程太慢了！"
    design_implication: "系统提供初始信任基线，压缩校准期从8周→2周，提供数据驱动建议而非需要用户摸索"
    resolution_strategy: "Initial trust baseline provision, data-driven recommendations, accelerated calibration"
    downstream_impact: "新手因缺乏指导往往默认过度信任"

  - id: UF022
    mr_id: MR9
    user_id: I17
    category: "Trust Calibration - Domain-Specific Zero Tolerance"
    description: "法律领域零容忍 - 无法安全使用AI"
    severity: 5/5
    time_cost: "Complete avoidance of AI for legal work"
    frequency: "All legal tasks"
    affected_domain: "Legal Practice"
    quote: "法律是0容忍错误领域。即使AI 95%准确，那5%错误可能导致客户败诉、律所被起诉、我执照吊销。所以我规则：法律问题AI信任度=0%。但这意味着我无法用AI节省时间。我希望AI能标注'这是高风险法律建议'，这样我就知道怎么定位它的角色。"
    design_implication: "域特定风险标记（Legal/Medical/Finance = 高风险），显式警告'需要专业人士验证'，建议'仅作初始研究参考'"
    resolution_strategy: "Domain-specific risk marking, explicit professional verification requirements"
    downstream_impact: "完全拒绝使用AI处理任何法律问题"

  # ============ MR2: 过程透明性与可追溯性 (76% affected) ============

  - id: UF023
    mr_id: MR2
    user_id: I5
    category: "Process Transparency - Black-Box Iteration"
    description: "代码改进黑盒 - 45分钟手动对比"
    severity: 4/5
    time_cost: "45 minutes per comparison"
    frequency: "Frequent code revisions"
    affected_domain: "Data Analysis"
    quote: "GPT改进了我的分析代码，输出更短更快。但问题：我不知道它做了什么改变！我打开了'before'和'after'并排，逐行对比寻找差异。这花了45分钟。如果有Git一样的diff视图就太好了。"
    design_implication: "自动diff视图，突出显示changes (additions, deletions, modifications)，时间线显示演变，允许逐版本比较"
    resolution_strategy: "Automated diff visualization, change history tracking, timeline view"
    downstream_impact: "无法理解AI的改进过程，学习收益减少"

  - id: UF024
    mr_id: MR2
    user_id: I11
    category: "Process Transparency - Hidden Reasoning"
    description: "推理过程不透明 - 无法判断逻辑健全性"
    severity: 4/5
    time_cost: "Verification time required"
    frequency: "Complex multi-step problems"
    affected_domain: "Research"
    quote: "我问GPT一个复杂问题，它给了答案。但我想理解思考过程 - 没有展示。只是最终答案，没有中间步骤。这让我很难判断逻辑是否健全。如果它能显示'第一步：...，第二步：...'就好了。"
    design_implication: "强制显示中间推理步骤（Chain-of-Thought），标注关键决策点，解释为何选择某方法而非其他"
    resolution_strategy: "Explicit reasoning step display, decision point annotation, method justification"
    downstream_impact: "信任度低，需要完整验证"

  - id: UF025
    mr_id: MR2
    user_id: I29
    category: "Process Transparency - Version Control Failure"
    description: "论文版本管理 - 好的版本被覆盖"
    severity: 4/5
    time_cost: "Re-generation of lost work"
    frequency: "Multi-round refinement projects"
    affected_domain: "Academic Writing"
    quote: "我和AI多轮交互优化论文初稿。3天后，我想回到'之前更好的版本'。但我没有保存每个版本！只能要求AI重新生成，结果还是不一样。系统应该自动保存版本历史。"
    design_implication: "自动版本快照，允许回溯到任意点，版本对比，导出完整交互历史"
    resolution_strategy: "Automatic version snapshots, version comparison, full session export"
    downstream_impact: "失去之前更好的工作成果"

  # ============ MR3: 人类能动性保护 (55% affected) ============

  - id: UF026
    mr_id: MR3
    user_id: I7
    category: "Agency Preservation - AI Overwhelm"
    description: "AI信息过载 - 替代了思考过程"
    severity: 4/5
    time_cost: "Processing unnecessary information"
    frequency: "Regular interactions"
    affected_domain: "Consulting"
    quote: "我问GPT一个简单问题。它给了5页答案，包括案例、理论、建议。我没要这么多！我只想思考5分钟就够了。现在被信息淹没。感觉AI在替我思考，而不是帮我思考。"
    design_implication: "用户可控制AI干预强度（passive, suggestive, proactive），默认简洁响应，用户请求更多细节，保持思考空间"
    resolution_strategy: "Adjustable intervention intensity, concise default responses, user-driven elaboration"
    downstream_impact: "缺乏独立思考空间，创意受阻"

  - id: UF027
    mr_id: MR3
    user_id: I19
    category: "Agency Preservation - Creative Authorship Loss"
    description: "设计创意被虚化 - 身份焦虑"
    severity: 4/5
    time_cost: "Identity and professional role uncertainty"
    frequency: "Creative task type"
    affected_domain: "Design"
    quote: "我问GPT'网站设计方向'。它直接给了完整设计方案。我应该说'thanks'吗？还是改进？感觉我的设计角色被虚化了。我有点担心：我还是设计师吗？现在我只是'修改AI方案的人'。"
    design_implication: "AI建议但需用户明确批准，默认状态：显示建议但不自动应用，允许用户拒绝或修改，明确标识AI生成vs用户创作"
    resolution_strategy: "Explicit approval mechanism, clear AI vs human authorship marking, user override capability"
    downstream_impact: "创意所有权丧失感，职业自信心下降"

  - id: UF028
    mr_id: MR3
    user_id: I37
    category: "Agency Preservation - Student Dependency Formation"
    description: "学生自主思考能力退化 - 教学观察"
    severity: 5/5
    time_cost: "Long-term learning outcome impact"
    frequency: "Systematic pattern"
    affected_domain: "Education"
    quote: "[Teacher observation] 学生以前：先试做作业，困难时来办公室。现在：直接问ChatGPT，有了答案再来找我。他们说'AI给了框架，我不确定对不对'。我注意到：学生的独立思考能力在退化。他们依赖AI验证，而不是相信自己。长期看，这对学习有害。"
    design_implication: "教育模式特殊设计，学习任务强制先独立尝试，AI作为验证而非替代，监控独立思考比例"
    resolution_strategy: "Forced independent attempt requirement, AI as verification tool, independence tracking"
    downstream_impact: "学生依赖性增加，独立学习能力下降"

  # ============ MR5: 低成本迭代机制 (33% affected) ============

  - id: UF029
    mr_id: MR5
    user_id: I27
    category: "Low-Cost Iteration - Style Variation Tedium"
    description: "文案风格尝试低效 - 20分钟完成可5分钟任务"
    severity: 4/5
    time_cost: "5 minutes could be 20 minutes"
    frequency: "Regular writing tasks"
    affected_domain: "Content Writing"
    quote: "我想看同一段落的3种风格：正式、口语化、幽默。我的做法：1. 问GPT'给我正式版本' 2. 复制到文档A 3. 回到ChatGPT 4. 新会话'给我口语版本' 5. 复制到文档B 6. 再来一个...然后在3个文档间切换对比。这太低效了！系统应该一次生成3个版本并排显示。"
    design_implication: "批量生成变体，一次请求多个风格/版本，并排比较视图，用户标记'最佳''可行''差'"
    resolution_strategy: "Batch variant generation, side-by-side comparison, version scoring"
    downstream_impact: "需要多轮提问，总时间长"

  - id: UF030
    mr_id: MR5
    user_id: I35
    category: "Low-Cost Iteration - Parameter Tuning Inefficiency"
    description: "代码质量参数优化 - 10次迭代30-50分钟"
    severity: 4/5
    time_cost: "30-50 minutes for parameter exploration"
    frequency: "Code optimization tasks"
    affected_domain: "Programming"
    quote: "我在优化GPT代码质量。试过改提示词、改温度参数...每次改一个变量，重新问GPT，等待回复。一个实验需要10次迭代，每次3-5分钟。如果系统能'一次扫描温度0.3-0.8，看5个不同输出'就好了。"
    design_implication: "参数扫描工具，自动测试不同温度/长度值，显示变化影响，用户快速选择最佳参数"
    resolution_strategy: "Parameter sweep tool, automated parameter testing, visual impact display"
    downstream_impact: "无法有效优化AI参数"

  # ============ MR8: 任务特征识别 (57% affected) ============

  - id: UF031
    mr_id: MR8
    user_id: I10
    category: "Task Characteristic Recognition - Unknown Verification Depth"
    description: "不知道该验证多深 - 练习vs考试"
    severity: 4/5
    time_cost: "Wasted verification effort or dangerous skipping"
    frequency: "Multiple task types"
    affected_domain: "Academic Learning"
    quote: "不同任务对验证的要求不一样。练习题：'快给我答案，我自己试试'；考试题：'必须100%确定'；头脑风暴：'任何创意都可以'。但GPT不知道这个背景。它对练习题的认真程度和考试题一样。浪费时间。"
    design_implication: "任务维度识别（重要性、熟悉度、时间压力），自适应严谨度和验证要求"
    resolution_strategy: "Task dimension detection, adaptive rigor level, context-aware verification requirements"
    downstream_impact: "无法根据任务类型优化AI使用"

  - id: UF032
    mr_id: MR8
    user_id: I24
    category: "Task Characteristic Recognition - Urgent Task Handling"
    description: "紧急任务处理不当 - 需快速草稿反而精品"
    severity: 4/5
    time_cost: "10 minutes generation when 3 minutes suffices"
    frequency: "Urgent/deadline scenarios"
    affected_domain: "Business"
    quote: "我有紧急提案，今天截止。我需要初稿。但GPT按照'最优质量'来生成，花了10分钟。我需要的是'可用初稿'，3分钟就够。系统应该问我'这有多紧急？'然后相应调整响应时间和详细度。"
    design_implication: "时间压力识别，自适应详细度和质量权衡，'快速草稿模式'vs'精品模式'"
    resolution_strategy: "Time pressure detection, quality vs speed tradeoff, quick draft mode"
    downstream_impact: "在时间压力下无法有效使用AI"

  # ============ MR12: 批判性思维脚手架 (49% affected) ============

  - id: UF033
    mr_id: MR12
    user_id: I13
    category: "Critical Thinking - No Evaluation Framework"
    description: "无法自主评价AI答案 - 全信或全不信"
    severity: 4/5
    time_cost: "Passive acceptance or rejection"
    frequency: "Complex topics"
    affected_domain: "Academic Learning"
    quote: "我问GPT一个政治问题，它给了答案。答案看起来合理，但我自己没想过。我怎么知道对不对？我没有框架来评价AI的答案质量。所以要么全信，要么全不信。没有中间地带。"
    design_implication: "批判性思维提示（假设是什么？有反例吗？逻辑完整吗？），领域特定检查清单，苏格拉底式引导"
    resolution_strategy: "Critical thinking prompts, domain-specific checklists, Socratic questioning"
    downstream_impact: "被动接受或拒绝，无真正理解"

  - id: UF034
    mr_id: MR12
    user_id: I30
    category: "Critical Thinking - Data Claim Verification"
    description: "数据声称未验证 - 缺乏评估框架"
    severity: 4/5
    time_cost: "Verification time required"
    frequency: "Data-driven decisions"
    affected_domain: "Business Analysis"
    quote: "我用AI做市场分析。它说'市场规模预计到2025年达$X B'。这个数据从哪来？怎么评估可信度？系统应该教我问题：这个估计基于什么假设？有多少信心？哪些因素会改变预测？"
    design_implication: "数据来源标注，假设透明化，不确定性指示，评估框架指导"
    resolution_strategy: "Source attribution, assumption transparency, uncertainty indicators, evaluation framework"
    downstream_impact: "数据驱动决策缺乏关键检验"

  # ============ MR14: 引导反思机制 (29% affected) ============

  - id: UF035
    mr_id: MR14
    user_id: I31
    category: "Guided Reflection - Learning Without Consolidation"
    description: "学习无反思 - 知识无巩固"
    severity: 4/5
    time_cost: "Long-term learning outcome"
    frequency: "Continuous learning sessions"
    affected_domain: "Knowledge Acquisition"
    quote: "我用AI学习新概念。会话结束，我继续忙别的。过了一周，我意识不起自己学了什么。对学习没有深化。系统应该在会话结束时问：'你理解了什么？还有什么不清楚？'这会帮我巩固知识。"
    design_implication: "会话结束反思提示，理解检查，困惑点识别，学习日志自动保存"
    resolution_strategy: "Post-session reflection prompts, understanding checks, confusion point identification"
    downstream_impact: "学习浮于表面，知识保留率低"

  - id: UF036
    mr_id: MR14
    user_id: I40
    category: "Guided Reflection - Strategy Evolution Unawareness"
    description: "策略演变无觉察 - 隐性改进"
    severity: 4/5
    time_cost: "Missed opportunity for deliberate improvement"
    frequency: "Long-term usage pattern"
    affected_domain: "AI Usage Optimization"
    quote: "我每天用AI处理许多问题。3个月后，同事问'你怎么用AI这么高效？'我想了想，才意识：我开发了一套方法。但我从未刻意反思过。系统应该定期问我：'你的AI使用策略变化了吗？在哪里改进了？'这会加速学习。"
    design_implication: "策略演变自动识别，定期反思提示，显式策略改进建议"
    resolution_strategy: "Strategy evolution detection, periodic reflection prompts, explicit improvement suggestions"
    downstream_impact: "改进被动隐性，无法有意识优化"

  # ============ MR15: 元认知策略指导 (67% affected) ============

  - id: UF037
    mr_id: MR15
    user_id: I4
    category: "Metacognitive Strategy - No Initial Guidance"
    description: "新手无使用指导 - 一个月浪费"
    severity: 5/5
    time_cost: "One month of inefficient learning"
    frequency: "All new users"
    affected_domain: "AI Usage Learning"
    quote: "我开始用AI。一上来就拼命问问题，复制结果。一个月后意识这样低效。好的做法：先自己想想，明确要什么，验证结果。但这个学习曲线很陡，我浪费了很多时间。系统应该从一开始就教我最佳实践。"
    design_implication: "新手教程，最佳实践演示，Just-in-time提示，渐进式释放支架"
    resolution_strategy: "Beginner tutorials, best practice demonstration, just-in-time prompts"
    downstream_impact: "一个月的学习浪费可避免"

  - id: UF038
    mr_id: MR15
    user_id: I20
    category: "Metacognitive Strategy - Dependency Formation"
    description: "依赖形成无觉察 - 顺序反了"
    severity: 5/5
    time_cost: "Long-term ability deterioration"
    frequency: "Continuous pattern"
    affected_domain: "Academic Learning"
    quote: "我发现自己越来越依赖AI。现在：AI → 问题? → AI → 最后review。之前：自己试 → 困难时问 → 理解后再做。顺序完全反了！我都没意识到这个变化。系统应该定期问我：'你多少任务是独立完成的？'提醒我保持平衡。"
    design_implication: "依赖监控，独立完成率追踪，定期提醒，行为模式警告"
    resolution_strategy: "Dependency monitoring, independence tracking, periodic reminders, pattern warnings"
    downstream_impact: "自主能力被慢慢蚕食"

  # ============ MR18: 过度依赖警告系统 ============

  - id: UF039
    mr_id: MR18
    user_id: I12
    category: "Over-Reliance Warning - Uncritical Acceptance"
    description: "[学生]无批判接受 - 模式F形成"
    severity: 5/5
    time_cost: "Long-term skill degradation"
    frequency: "Ongoing pattern"
    affected_domain: "Academic Learning"
    quote: "[Teacher observation] 这个学生开始时积极尝试自己做。现在每次卡住就问AI，接受第一个答案。成绩还不错，所以无意识地强化了这个模式。我很担心：长期看，独立学习能力会衰退。只是他现在没意识到。"
    design_implication: "模式F检测（连续无验证、短提示词、接受第一个输出），温和提醒→强制干预，反思提示"
    resolution_strategy: "Pattern F detection, graduated intervention, forced reflection"
    downstream_impact: "无意识能力退化，危险隐性"

  - id: UF040
    mr_id: MR18
    user_id: I44
    category: "Over-Reliance Warning - Technical Debt"
    description: "[工程观察]无批判代码接受 - 风险累积"
    severity: 5/5
    time_cost: "Future technical debt"
    frequency: "Systemic pattern"
    affected_domain: "Software Development"
    quote: "[Team lead observation] 我看到团队成员直接复制AI代码，从不质疑或测试。'它看起来合理'就足够了。这很危险。最终会有安全漏洞或性能问题，但他们没意识到这个模式。"
    design_implication: "代码复制警告，强制代码审查流程，测试要求，安全检查"
    resolution_strategy: "Code copy warning, mandatory review process, testing requirements"
    downstream_impact: "技术债务隐形累积"

  - id: UF041
    mr_id: MR18
    user_id: I26
    category: "Over-Reliance Warning - Clinical Risk"
    description: "[医学]临床决策AI依赖 - 患者安全风险"
    severity: 5/5
    time_cost: "Patient safety implications"
    frequency: "Systematic risk"
    affected_domain: "Medical Practice"
    quote: "[Medical educator observation] 医学生开始用AI'辅助诊断'。一开始会验证，慢慢地时间压力和'AI通常对'的体验导致越来越相信AI的诊断列表。这非常危险。医学决策不能无批判接受。"
    design_implication: "医学域强制验证，多源确认要求，诊断人类最终责任声明"
    resolution_strategy: "Medical domain verification requirement, multi-source confirmation, physician accountability"
    downstream_impact: "患者安全风险"

  # ============ MR19: 元认知能力诊断 ============

  - id: UF042
    mr_id: MR19
    user_id: I9
    category: "Metacognitive Assessment - Monitoring Weakness"
    description: "规划强但监控弱 - 个性化支持需求"
    severity: 3/5
    time_cost: "Suboptimal support due to mismatch"
    frequency: "Continuous"
    affected_domain: "AI Usage Patterns"
    quote: "我很擅长规划，但在执行过程中很难监控理解。我的优势在于'怎样做'，但弱点在于'进度检查'。如果系统能识别这个，针对性地加强我的监控能力支持，就能更有效。"
    design_implication: "诊断规划/监控/评价/调节各维度，针对性支持（加强弱项，淡化强项），个性化学习路径"
    resolution_strategy: "Multi-dimensional metacognitive assessment, targeted support, personalized learning paths"
    downstream_impact: "通用支持可能无法最优"

  # ============ MR4: 角色定义指导 (39% affected) ============

  - id: UF043
    mr_id: MR4
    user_id: I6
    category: "Role Definition - Unclear Boundaries"
    description: "角色边界不清 - 协作摩擦高"
    severity: 4/5
    time_cost: "Frequent recalibration"
    frequency: "Repeated interactions"
    affected_domain: "Design"
    quote: "我用AI帮我设计。但什么时候让AI主导，什么时候我主导？什么时候相信它，什么时候质疑它？有时它超出了我想要的范围。我需要清楚地定义：'在这个任务中，你是我的助手做X，而不是做Y。'"
    design_implication: "角色模板库（研究助手、草稿生成器、验证工具、头脑风暴伙伴），显式角色协议，边界提示"
    resolution_strategy: "Role template library, explicit role agreements, boundary warnings"
    downstream_impact: "协作模式模糊，效率低"

  - id: UF044
    mr_id: MR4
    user_id: I23
    category: "Role Definition - Collaboration Model Ambiguity"
    description: "协作模式模糊 - 每次即兴"
    severity: 4/5
    time_cost: "Repeated negotiation"
    frequency: "Regular collaborations"
    affected_domain: "Content Creation"
    quote: "我和AI协作写文章。但我从不确定：它应该生成初稿给我改？还是给我灵感？我应该逐句审查还是只验证核心论点？每次感觉都在即兴，没有明确协议。"
    design_implication: "协作模式显式定义，分工明确，责任清晰，协议记录"
    resolution_strategy: "Explicit collaboration models, clear division of labor, responsibility clarification"
    downstream_impact: "低效的即兴协作"

  # ============ MR6: 跨模型实验 (24% affected) ============

  - id: UF045
    mr_id: MR6
    user_id: I48
    category: "Cross-Model Experimentation - Model Selection Difficulty"
    description: "无法追踪不同模型表现 - 性能数据缺失"
    severity: 3/5
    time_cost: "Decision difficulty"
    frequency: "Model selection decisions"
    affected_domain: "Development"
    quote: "用GPT生成代码时，有时得到差结果。我不知道：这是提示问题还是模型问题？换一个模型是否会更好？这个任务哪个模型最擅长？没有历史数据，我无法追踪不同模型在不同任务上的表现。"
    design_implication: "跨模型性能追踪，历史表现记录，模型推荐引擎，任务类型最佳模型建议"
    resolution_strategy: "Cross-model performance tracking, model recommendation engine, task-model matching"
    downstream_impact: "模型选择基于猜测"

  # ============ MR7: 失败容忍与学习机制 (18% affected) ============

  - id: UF046
    mr_id: MR7
    user_id: I32
    category: "Failure Tolerance - Discouragement from Failure"
    description: "失败导致沮丧放弃 - 实验心理成本高"
    severity: 4/5
    time_cost: "Opportunity cost from giving up"
    frequency: "Challenging tasks"
    affected_domain: "Entrepreneurship"
    quote: "我尝试用AI帮我写商业计划。第一版很差，没有用。我感到沮丧，放弃了。之后才意识：应该把这个'失败'看作学习。但系统对失败没有鼓励，导致我放弃得太快。"
    design_implication: "失败分析自动触发，'What went wrong?'反思，失败模式记录，鼓励继续尝试，失败重定义为学习"
    resolution_strategy: "Failure analysis prompt, learning reframing, encouragement mechanisms"
    downstream_impact: "过度保守，放弃可能成功的尝试"

  # ============ MR10: 成本效益决策支持 (27% affected) ============

  - id: UF047
    mr_id: MR10
    user_id: I25
    category: "Cost-Benefit Decision Support - Hidden Trade-offs"
    description: "时间vs质量权衡隐式 - 无法计算ROI"
    severity: 4/5
    time_cost: "Decision making difficulty"
    frequency: "Work planning"
    affected_domain: "Financial Analysis"
    quote: "我在考虑用AI快速生成初稿（2小时节省，质量60%）vs手工做精品（5小时，质量95%）。什么时候值得？系统应该帮我计算ROI：这个项目的迭代周期、客户对质量的敏感度等。"
    design_implication: "预测性分析（时间节省估计），质量风险评估，学习机会成本量化，情境建议（紧急vs学习任务差异）"
    resolution_strategy: "Predictive time/quality analysis, opportunity cost assessment, contextual recommendations"
    downstream_impact: "盲目追求速度或质量，决策非优"

  # ============ MR17: 学习过程可视化 ============

  - id: UF048
    mr_id: MR17
    user_id: I38
    category: "Learning Process Visualization - Progress Opacity"
    description: "学习进度无感 - 3个月无明确进步感"
    severity: 3/5
    time_cost: "Motivation impact"
    frequency: "Long-term learning"
    affected_domain: "Self-Learning"
    quote: "我用AI学习新领域。3个月过去了，我不知道自己进步了多少。是学得更深了还是只是接触了更多广度？系统应该可视化：新概念、能力增长、知识图谱成长。"
    design_implication: "知识图谱成长可视化，能力仪表盘（独立性、速度、质量），学习时间线，对比视图（开始vs现在）"
    resolution_strategy: "Knowledge graph visualization, ability dashboard, learning timeline, comparison views"
    downstream_impact: "缺乏进度反馈，学习动力不足"

  - id: UF049
    mr_id: MR17
    user_id: I47
    category: "Learning Process Visualization - Ability Growth Tracking"
    description: "编程能力增长无追踪 - 不知道独立性变化"
    severity: 3/5
    time_cost: "Unclear learning outcomes"
    frequency: "Learning projects"
    affected_domain: "Programming"
    quote: "我做了100个编程问题。但不知道：多少是独立完成的？多少完全依赖AI？我的独立能力实际上增长了多少？如果有个仪表盘显示这些指标就好了。"
    design_implication: "独立性追踪，能力轨迹显示，量化学习进度，vs基线对比"
    resolution_strategy: "Independence tracking, ability trajectory visualization, quantified progress"
    downstream_impact: "无法评估真实学习收获"

  # ============ MR23: 隐私保护架构 (35% affected) ============

  - id: UF050
    mr_id: MR23
    user_id: I33
    category: "Privacy - Financial Data Leakage Risk"
    description: "数据保密恐惧 - 金融交易信息"
    severity: 5/5
    time_cost: "Complete AI avoidance"
    frequency: "All financial analysis tasks"
    affected_domain: "Finance/Trading"
    quote: "我们想用AI分析交易策略。但法律部说：'不行。交易信息是机密。如果上传到云端，竞争者可能看到。'所以只能手工分析。失去了AI的价值。如果有本地运行的AI模型，我们就能用了。"
    design_implication: "本地推理选项，端到端加密，联邦学习支持，隐私架构分阶段实施（本地存储→本地推理→联邦学习→同态加密）"
    resolution_strategy: "On-premise inference option, end-to-end encryption, federated learning support"
    downstream_impact: "金融市场采纳完全被阻止"

  - id: UF051
    mr_id: MR23
    user_id: I17
    category: "Privacy - Professional Confidentiality"
    description: "律师保密义务 - 客户信息绝对保密"
    severity: 5/5
    time_cost: "Complete AI prohibition"
    frequency: "All client work"
    affected_domain: "Legal Practice"
    quote: "我的客户信息绝对保密。如果上传到ChatGPT，可能违反伦理规范。律所完全禁止用公共AI。自己搭本地AI？太贵了。解决方案：企业隐私AI选项"
    design_implication: "企业级隐私解决方案，成本平衡，HIPAA/合规支持"
    resolution_strategy: "Enterprise privacy solution, cost-effective deployment, compliance support"
    downstream_impact: "法律专业市场完全不可用"

end_of_catalog

# ============ 统计汇总 ============

summary:
  total_frustrations_documented: 51
  coverage_target: "At least 50 from 143 total"
  mr_distribution:
    MR13: 8  # Transparency of uncertainty
    MR11: 4  # Integrated verification
    MR16: 4  # Skill atrophy prevention
    MR1: 3   # Task decomposition
    MR9: 3   # Trust calibration
    MR2: 3   # Process transparency
    MR3: 3   # Agency preservation
    MR5: 2   # Low-cost iteration
    MR8: 2   # Task characteristic recognition
    MR12: 2  # Critical thinking scaffolding
    MR14: 2  # Guided reflection
    MR15: 2  # Metacognitive strategy
    MR18: 3  # Over-reliance warning
    MR19: 1  # Metacognitive assessment
    MR4: 2   # Role definition
    MR6: 1   # Cross-model experimentation
    MR7: 1   # Failure tolerance
    MR10: 1  # Cost-benefit decision
    MR17: 2  # Learning process visualization
    MR23: 2  # Privacy architecture

  severity_distribution:
    "5/5 (Critical)": 25
    "4/5 (High)": 25
    "3/5 (Medium)": 1

  affected_users_range: "9-48 out of 49"

  top_affected_mrs:
    - "MR13: 98% (48/49 users)"
    - "MR2: 76% (37/49 users)"
    - "MR9: 84% (41/49 users)"
    - "MR3: 55% (27/49 users)"
    - "MR1: 45% (22/49 users)"

  recommendations:
    immediate: "Implement MR13, MR2, MR15 for maximum impact (76-98% coverage)"
    high_priority: "Add MR11, MR16, MR1, MR9 for comprehensive solution (43-84% coverage)"
    medium_priority: "Implement remaining MRs for specialized use cases and long-term value"

metadata:
  validation_criteria:
    - "✓ Covers 51 frustrations (target: 50+)"
    - "✓ Every frustration has MR mapping"
    - "✓ Time cost documented (minutes/hours/days)"
    - "✓ Severity scored (3/5-5/5)"
    - "✓ User ID and domain specified"
    - "✓ Design implications clear"

  data_quality:
    sources: "Direct quotes from 49 interviews"
    coding_instances: "588 interview coded segments"
    reliability: "High - grounded in empirical data"
