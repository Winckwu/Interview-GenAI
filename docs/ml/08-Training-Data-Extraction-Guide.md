# 训练数据提取指南 (Training Data Extraction Guide)

> **目的**：从49份访谈转录中系统化提取元认知特征，用于ML模型训练  
> **理论基础**：扎根理论 + 12子过程元认知框架 (Flavell 1979; Azevedo & Hadwin 2005)  
> **信效度**：Cohen κ = 0.71 (实质一致)

---

## 📊 数据概览

### 样本特征

**最终样本**：N = 49
- **学生**：23人 (47%)
- **职场人士**：26人 (53%)
- **访谈时间**：2024年4月-8月
- **单场时长**：45-93分钟，均值56.2分钟，SD=12.7
- **总字数**：743,291字，单场均值15,168字

**理论饱和**：
- 第35场访谈：模式开始稳定
- 后续14场：验证模式普遍性

**地域分布**：
- 新加坡：24人 (49%)
- 中国内地：15人 (31%)
- 其他国际：10人 (20%)

**学科背景**：
- 理工：26人 (53%)
- 商科：17人 (35%)
- 人文：3人 (6%)
- 创意：3人 (6%)

---

## 🔬 三阶段编码过程

### 阶段1: 开放编码 (Open Coding)

**目标**：识别初始概念和临时类别

**过程**：
```
49份访谈转录 
→ 逐行阅读，标记元认知相关行为
→ 生成 387个初始代码
→ 归纳为 12个临时类别
→ 产出 588个编码实例（49人 × 12子过程）
```

**示例**：
```
转录片段："我会先把大任务拆成几个小块，每个小块我都先自己想一想应该怎么做..."

初始编码：
- "任务分解"
- "前期规划"
- "独立思考优先"
- "结构化方法"

临时归类 → P1: Task Decomposition（规划类）
```

---

### 阶段2: 聚焦编码 (Focused Coding)

**目标**：构建系统化的12子过程元认知框架

#### **12子过程元认知框架** ⭐核心框架⭐

改编自Flavell (1979), Schraw & Dennison (1994), Azevedo & Hadwin (2005)

```
┌─────────────────────────────────────────────────────────┐
│               元认知的12个子过程                          │
│          (12 Metacognitive Sub-Processes)                │
└─────────────────────────────────────────────────────────┘

1️⃣ 规划 (Planning) - 4个子过程
   ├─ P1: 任务分解 (Task Decomposition)
   │     定义：将复杂任务拆解为可管理的子任务
   │     行为：列清单、画流程图、确定优先级
   │
   ├─ P2: 目标设定 (Goal Setting)
   │     定义：明确定义预期结果和成功标准
   │     行为："我要达到什么结果"、"什么叫做完成"
   │
   ├─ P3: 策略选择 (Strategy Selection)
   │     定义：选择适合任务的方法和工具
   │     行为："这种任务最好用...方法"
   │
   └─ P4: 角色定义 (Role Definition)
        定义：界定人类vs AI的责任边界
        行为："AI负责X，我负责Y"、"这部分不能外包"

2️⃣ 监控 (Monitoring) - 3个子过程
   ├─ M1: 过程追踪 (Progress Tracking)
   │     定义：持续评估"我做到哪一步了"
   │     行为：检查完成度、时间管理、里程碑核对
   │
   ├─ M2: 质量检查 (Quality Checking)
   │     定义：实时评估输出是否符合标准
   │     行为："这个答案对吗"、"逻辑通顺吗"
   │
   └─ M3: 信任校准 (Trust Calibration)
        定义：动态调整对AI输出的信任程度
        行为："这次它靠谱吗"、"需要验证吗"

3️⃣ 评价 (Evaluation) - 3个子过程
   ├─ E1: 输出质量评估 (Output Quality Assessment)
   │     定义：任务完成后的全面质量判断
   │     行为：与标准对照、同行评审、专家验证
   │
   ├─ E2: 风险评估 (Risk Assessment)
   │     定义：识别潜在错误和后果
   │     行为："如果这个错了会怎样"、"哪里最可能有问题"
   │
   └─ E3: 能力判断 (Capability Judgment)
        定义：评估"我（不用AI）能做到什么程度"
        行为：能力自测、独立尝试、基线对比

4️⃣ 调节 (Regulation) - 2个子过程
   ├─ R1: 策略调整 (Strategy Adjustment)
   │     定义：根据反馈修改方法
   │     行为："这个不行，换个方式"、迭代改进
   │
   └─ R2: 工具切换 (Tool Switching)
        定义：在不同AI/工具间灵活切换
        行为：跨模型实验、工具组合、降级到手工
```

---

#### **编码一致性检验**

**过程**：
- 3名研究者独立对20%样本（10份转录）进行编码
- 计算Cohen's Kappa系数

**结果**：
- **Cohen κ = 0.71** (实质一致, Substantial Agreement)
- 分歧讨论并完善编码手册
- 剩余80%由主研究者编码

---

#### **证据强度判定** (3级评分)

对每个受访者的每个子过程，判定证据强度：

```
✓✓✓ 强证据 (Strong Evidence)
条件：
1. 明确的语言描述 ("我总是..."、"我的习惯是...")
2. 具体行为示例 (≥2个)
3. 可观察的行为模式
4. 持续性/习惯化（不是偶然）

示例：
"我每次用GPT之前，都会先花10分钟自己列一个提纲，
想清楚哪些部分我自己能做，哪些需要AI帮忙。
比如上周写proposal，我自己定了研究问题和方法，
只让GPT帮我润色语言。"
→ P1(✓✓✓), P4(✓✓✓)

---

✓✓ 中等证据 (Moderate Evidence)
条件：
1. 有描述但不够具体
2. 仅1个示例
3. 行为存在但不稳定

示例：
"我有时会检查一下AI的回答是不是合理，
但不是每次都检查，看情况吧。"
→ M2(✓✓)

---

✓ 弱证据 (Weak Evidence)
条件：
1. 仅有意识但无行为
2. 模糊表述 ("可能"、"应该")
3. 知道应该做但承认不做

示例：
"我知道应该验证AI的引用，但老实说，
我通常没时间，就直接用了。"
→ M2(✓) - 有意识，无行为

---

✗ 无证据 (No Evidence)
条件：
1. 未提及该子过程
2. 明确否认 ("从不..."、"没想过...")
3. 不知道该策略存在

示例：
访谈者："你用AI之前会先规划一下任务吗？"
受访者："不会诶，我就是想到什么问什么。"
→ P1(✗)
```

---

### 阶段3: 理论编码 (Theoretical Coding)

**目标**：将12子过程聚类为6种元认知模式

#### **聚类分析方法**

1. **构建特征矩阵**：
   ```
   49行（受访者） × 12列（子过程）
   每个单元格：证据强度分数
   - ✓✓✓ = 3分
   - ✓✓ = 2分
   - ✓ = 1分
   - ✗ = 0分
   ```

2. **层次聚类**：
   - 方法：Ward's method
   - 距离：Euclidean distance
   - 评估指标：Silhouette Coefficient

3. **确定最优聚类数**：
   ```
   测试K=3到K=8的解
   
   Silhouette Coefficient:
   K=3: 0.41
   K=4: 0.45
   K=5: 0.48
   K=6: 0.52 ← 最高！
   K=7: 0.49
   K=8: 0.44
   
   → 选择6类解
   ```

4. **质性验证**：
   - 6轮团队讨论（3名研究者）
   - 检查类别内部一致性
   - 命名每个模式（Pattern A-F）
   - 撰写模式描述

---

## 📋 完整编码手册 (Codebook)

### P1: 任务分解 (Task Decomposition)

**定义**：将复杂任务拆解为可管理的子任务序列

**强证据行为**：
- 明确列出子任务清单
- 绘制任务流程图/思维导图
- 使用项目管理工具（Notion, Trello）
- 能够清晰解释"为什么这样分解"

**编码示例**：
```
✓✓✓ 强：
"我写论文都是先列大纲，分成introduction, method, results...
每个部分再细分。比如method部分，我会分成participants, 
procedure, analysis...然后逐个击破。"
(受访者I3)

✓✓ 中：
"我会把任务分成几个部分，但没有很详细的规划。"

✓ 弱：
"我知道应该分解任务，但实际上很少做。"

✗ 无：
"我从来不分解，想到什么做什么。"
```

**与ML特征的映射**：
→ `taskDecompositionScore` (0-3分)

---

### P2: 目标设定 (Goal Setting)

**定义**：明确定义预期结果和成功标准

**强证据行为**：
- SMART目标（具体、可测量、可达成、相关、有时限）
- 明确"完成"的定义
- 设定质量阈值

**编码示例**：
```
✓✓✓ 强：
"我这次的目标是写一个2000字的literature review，
至少引用15篇peer-reviewed文章，deadline是周五晚上。
质量标准是导师能直接用在我们的grant proposal里。"
(受访者I22)

✓✓ 中：
"我想写一个差不多的literature review，尽量快点完成。"

✓ 弱：
"我就是想了解一下这个话题。"

✗ 无：
"没有具体目标，随便看看。"
```

**与ML特征的映射**：
→ 间接影响 `promptSpecificity`（目标越清晰，提示越具体）

---

### P3: 策略选择 (Strategy Selection)

**定义**：根据任务特性选择适合的方法、工具、AI模型

**强证据行为**：
- 主动比较不同方法的优劣
- 能够解释"为什么选这个工具/模型"
- 根据任务调整策略

**编码示例**：
```
✓✓✓ 强：
"代码调试我用GPT-4，因为它逻辑强。
创意写作我用Claude，因为它文风好。
数学证明我用Wolfram Alpha验算，不太信LLM。"
(受访者I41)

✓✓ 中：
"我主要用ChatGPT，偶尔试试别的。"

✓ 弱：
"我只用ChatGPT，没想过用别的。"

✗ 无：
"我不知道还有其他工具。"
```

**与ML特征的映射**：
→ `strategyDiversity` (使用工具/模型的种类)
→ `crossModelUsage` (是否跨模型比较)

---

### P4: 角色定义 (Role Definition)

**定义**：明确界定人类vs AI的责任边界

**强证据行为**：
- 清晰的"AI做什么，我做什么"规则
- 有"禁区"（某些事坚决不让AI做）
- 保持最终决策权在人类

**编码示例**：
```
✓✓✓ 强：
"我有明确的规则：AI可以帮我brainstorm, draft, polish，
但不能替我做final decision。
比如选择研究问题这种，必须是我自己思考的。"
(受访者I12)

✓✓ 中：
"我大概知道哪些该AI做，哪些该我做，但没有明确规则。"

✓ 弱：
"我没太想过这个问题。"

✗ 无：
"AI能做的都让它做，省事。"
```

**与ML特征的映射**：
→ 影响 `independentAttemptRate`（保留边界的用户会先尝试独立完成）

---

### M1: 过程追踪 (Progress Tracking)

**定义**：持续监控任务进度

**强证据行为**：
- 使用进度条/checklist
- 时间管理（"还有X分钟"）
- 里程碑检查

**编码示例**：
```
✓✓✓ 强：
"我用Notion追踪进度，每完成一个子任务就打勾。
我会估计每部分的时间，实际做的时候对照计划。"
(受访者I8)

✓✓ 中：
"我大概知道自己做到哪了，但没有系统化的追踪。"

✓ 弱：
"我很少关注进度，做完就算。"

✗ 无：
"从不追踪进度。"
```

**与ML特征的映射**：
→ 间接影响session duration patterns

---

### M2: 质量检查 (Quality Checking)

**定义**：实时评估AI输出质量

**强证据行为**：
- 逐行审查AI代码/文本
- 逻辑检查（"这说得通吗？"）
- 运行测试/验证

**编码示例**：
```
✓✓✓ 强：
"GPT给我代码，我不会直接用。我会逐行读，理解它在干什么，
然后在本地跑一遍，测试edge cases。
经常发现bug，它不是总对的。"
(受访者I44)

✓✓ 中：
"我会大概看一眼，觉得合理就用了。"

✓ 弱：
"我知道应该检查，但通常懒得做。"

✗ 无：
"直接复制粘贴，从不检查。"
```

**与ML特征的映射**：
→ `verificationRate` (核心特征！)

---

### M3: 信任校准 (Trust Calibration)

**定义**：动态调整对AI的信任水平

**强证据行为**：
- 信任水平随任务类型变化
- 发现错误后降低信任
- 能够articulate信任逻辑

**编码示例**：
```
✓✓✓ 强：
"我对GPT的信任不是固定的。
数学我信30%，必须验算；
代码我信70%，理解后就用；
头脑风暴我信90%，就是要发散嘛。"
(受访者I33, Pattern C典型)

✓✓ 中：
"我对它的信任有点波动，但说不清规律。"

✓ 弱：
"我基本都信它。"

✗ 无：
"AI怎么可能错？"（Pattern F危险信号！）
```

**与ML特征的映射**：
→ `trustCalibrationAccuracy` (信任是否匹配实际AI能力)

---

### E1: 输出质量评估 (Output Quality Assessment)

**定义**：任务完成后的全面质量判断

**强证据行为**：
- 多维度评估（内容、格式、逻辑、风格）
- 与标准/范例对照
- 寻求外部反馈

**编码示例**：
```
✓✓✓ 强：
"写完之后我会对照rubric逐项检查，
然后给同学看，听他们的反馈，再改。
我不会满足于'看起来差不多'。"
(受访者I26)

✓✓ 中：
"我会评估一下质量，但不是很系统。"

✓ 弱：
"大概看一眼，觉得还行就提交了。"

✗ 无：
"做完就算，不评估。"
```

**与ML特征的映射**：
→ 影响 `modificationRate`（高质量标准→高修改率）

---

### E2: 风险评估 (Risk Assessment)

**定义**：识别潜在错误和后果严重性

**强证据行为**：
- 主动寻找"哪里可能出错"
- 评估错误后果（"如果这错了会怎样？"）
- 针对高风险部分加强验证

**编码示例**：
```
✓✓✓ 强：
"这是要交给客户的代码，如果有bug会影响公司声誉。
所以我特别仔细，尤其是security相关的部分，
每一行都review，还让同事帮我看。"
(受访者I38)

✓✓ 中：
"我会想想哪里可能有问题，但不太系统。"

✓ 弱：
"很少想风险，出了问题再说。"

✗ 无：
"从没想过风险。"
```

**与ML特征的映射**：
→ 影响 `verificationRate`（高风险任务→高验证率）

---

### E3: 能力判断 (Capability Judgment)

**定义**：评估"不用AI我能做到什么程度"

**强证据行为**：
- 定期自测独立能力
- 能够准确评估自己的技能水平
- 觉察能力变化（提升或退化）

**编码示例**：
```
✓✓✓ 强：
"每个月我会给自己一个coding challenge，
不用AI，纯手工写，看看我还能不能做。
如果发现某个知识点忘了，我会专门去复习。"
(受访者I3, Pattern A典型)

✓✓ 中：
"我大概知道自己能做什么，但没有系统测试过。"

✓ 弱：
"我觉得我挺厉害的，但没验证过。"（过度自信）

✗ 无：
"从没想过这个问题。"（Pattern F危险！）
```

**与ML特征的映射**：
→ `errorAwareness`（能力判断准确→能发现AI错误）
→ 影响skill baseline testing行为

---

### R1: 策略调整 (Strategy Adjustment)

**定义**：根据反馈灵活修改方法

**强证据行为**：
- 快速迭代（"这个不行，试试那个"）
- 从失败中学习
- 记录"什么有效、什么无效"

**编码示例**：
```
✓✓✓ 强：
"第一次提示没得到好结果，我会换个角度重问。
通常3-5次迭代能找到有效的提示模式。
我有个文档记录不同任务的best practices。"
(受访者I16, Pattern B典型)

✓✓ 中：
"不行就换个方式，但没有系统化的调整。"

✓ 弱：
"我会调整，但通常是随机尝试。"

✗ 无：
"一次不行就放弃了。"
```

**与ML特征的映射**：
→ `iterationFrequency`（核心特征！）

---

### R2: 工具切换 (Tool Switching)

**定义**：在AI工具、非AI工具、手工方法间灵活切换

**强证据行为**：
- 跨模型比较（ChatGPT vs Claude vs Gemini）
- AI失效时降级到传统工具（Google, 教材）
- 组合使用（AI草稿 + 人工精修）

**编码示例**：
```
✓✓✓ 强：
"如果GPT给的代码有bug，我会：
1) 试试Claude看它怎么写
2) Google错误信息去Stack Overflow
3) 查官方文档
4) 如果都不行，自己debug
我不会死磕一个工具。"
(受访者I22, Pattern C典型)

✓✓ 中：
"偶尔会换个工具试试。"

✓ 弱：
"基本只用一个工具。"

✗ 无：
"只用ChatGPT，没想过用别的。"
```

**与ML特征的映射**：
→ `crossModelUsage`
→ `strategyDiversity`

---

## 🎯 从12子过程到12维ML特征的映射

### 直接映射（1:1）

| 子过程 | ML特征 | 计算方法 |
|--------|--------|----------|
| P1 | `taskDecompositionScore` | 证据强度 (0-3分) |
| M2 | `verificationRate` | #验证行为 / #总交互 |
| R1 | `iterationFrequency` | #迭代 / session时长 |
| R2 | `crossModelUsage` | 使用模型种类数 |
| E3 | `errorAwareness` | 自我报告 + 独立测试表现 |
| P3+R2 | `strategyDiversity` | 策略种类数 |

### 复合映射（多:1）

| ML特征 | 影响子过程 | 计算逻辑 |
|--------|-----------|---------|
| `promptSpecificity` | P2, P3 | 提示词长度 + 具体性得分 |
| `modificationRate` | M2, E1 | #修改 / #接受 |
| `reflectionDepth` | E1, E2, E3 | 反思语句数量+深度 |
| `trustCalibrationAccuracy` | M3 | \|实际信任 - 应有信任\| |
| `independentAttemptRate` | P4, E3 | #先尝试后AI / #总任务 |
| `timeBeforeAIQuery` | P1, P4 | 任务开始到首次查询的时间 |

---

## 🔍 边界案例判定规则

### 案例1：混合模式用户

**情境**：受访者I28在不同任务展现不同模式
- 学术论文 → Pattern A行为
- 课堂作业 → Pattern C行为

**判定**：
1. 识别"主导模式"（最频繁/最一致）→ Pattern C
2. 标注"次要模式"→ Pattern A
3. 在训练数据中：
   - 用主导模式打标签
   - 在notes字段记录混合特征
   - 如果两种模式都很强，拆分为2条训练样本

---

### 案例2：低证据强度

**情境**：受访者I35对大部分子过程只有✓或✗，很少✓✓✓

**判定**：
- 如果总分<15分（12子过程平均<1.25） → 归类为Pattern F或排除（不典型样本）
- 保留作为"边缘案例"，用于测试集而非训练集

---

### 案例3：意识-行为脱节

**情境**：受访者I42说"我知道应该验证AI输出"，但承认"实际很少验证"

**判定**：
- 陈述性知识 ≠ 程序性技能
- 编码按**实际行为**，不是意识/意图
- I42的M2 → ✓（有意识，无行为）

参考：外部专家审查强调的"knowing vs doing"区分

---

### 案例4：文化/语言差异

**情境**：普通话访谈用户的提示词普遍更短

**判定**：
- `promptSpecificity`需要语言归一化
- 计算：(字符数 / 语言基准) × 具体性得分
- 中文基准：均值45字符
- 英文基准：均值120字符

---

## 📊 质量控制清单

### 编码前

- [ ] 阅读完整转录（不要只看摘要）
- [ ] 参考访谈者备忘录（了解语气、情绪）
- [ ] 查看屏幕录制（如有）验证行为描述

### 编码中

- [ ] 每个子过程必须有文本证据支持
- [ ] 引用具体段落（行号）
- [ ] 区分"陈述性知识"vs"程序性技能"
- [ ] 不确定时标记为"待讨论"

### 编码后

- [ ] 计算12子过程总分（应在0-36之间）
- [ ] 检查内部一致性（如P1高但P2低→合理吗？）
- [ ] 对照已有案例（与同模式其他用户相似吗？）
- [ ] 如果是前20%样本，等待团队验证

---

## 🎓 信效度保障措施

### 1. 成员核对 (Member Checking)

**过程**：
- 选择10名受访者（5名高效用户 + 5名挣扎用户）
- 发送模式描述和分类结果
- 询问："这个描述符合你的使用方式吗？"

**结果**：
- 9人认可分类
- 1人（I28）指出情境切换→修订Pattern C定义

---

### 2. 研究者三角验证 (Investigator Triangulation)

**过程**：
- 3名研究者独立编码20%样本（10份转录）
- 计算Cohen's Kappa

**结果**：
- Cohen κ = 0.71 (实质一致)
- 分歧案例讨论→完善编码手册
- 主研究者完成剩余80%

---

### 3. 理论三角验证 (Theoretical Triangulation)

**理论基础**：
- Flavell (1979): 元认知原创框架
- Schraw & Dennison (1994): 元认知量表
- Azevedo & Hadwin (2005): 自我调节学习

**验证**：12子过程与已有理论高度一致

---

### 4. 数据三角验证 (Data Triangulation)

**多数据源**：
- 访谈逐字稿（主要）
- 访谈者备忘录（辅助：语气、情绪）
- 屏幕录制（14例：验证行为描述）

---

## ⚠️ Pattern F的特殊处理

### 问题：训练数据缺失

- **现状**：49人样本中，无人将Pattern F作为主导模式
- **原因**：最大差异抽样偏差（愿意参与深度访谈者通常已有元认知策略）
- **风险**：ML模型无法识别Pattern F

### 解决方案：合成数据生成

#### 方案1：规则引擎（短期）

基于Pattern F定义创建检测规则：
```python
def detect_pattern_f(metrics):
    red_flags = 0
    
    if metrics['verificationRate'] < 0.10:
        red_flags += 3  # 极低验证率
    if metrics['promptSpecificity'] < 5:
        red_flags += 2  # 极简提示
    if metrics['errorAwareness'] < 0.20:
        red_flags += 3  # 无法发现AI错误
    if metrics['iterationFrequency'] < 0.15:
        red_flags += 2  # 从不迭代
    if metrics['independentAttemptRate'] < 0.10:
        red_flags += 3  # 不尝试独立完成
    
    if red_flags >= 8:
        return 'Pattern F (high confidence)'
    elif red_flags >= 5:
        return 'Pattern F (moderate confidence)'
    else:
        return None
```

#### 方案2：专家模拟（中期）

- 邀请3位教师提供"挣扎学生"的匿名行为日志
- 不需要访谈，只需行为数据（保护学生隐私）
- 预期10-15个Pattern F样本

#### 方案3：对抗生成（长期，Paper 3）

基于Pattern A-E训练GAN，生成"反向特征"
- 低验证率
- 低迭代频率
- 低反思深度
- ...

---

## 📁 数据输出格式

### 训练数据CSV结构

```csv
user_id,pattern,p1,p2,p3,p4,m1,m2,m3,e1,e2,e3,r1,r2,total_score,confidence,notes
I001,A,3,3,2,3,2,3,2,2,2,3,2,2,29,high,"典型Pattern A, 明确边界维护"
I002,C,2,2,3,2,3,2,3,3,3,2,3,3,31,high,"情境敏感, 信任动态校准"
...
```

### 特征向量JSON结构

```json
{
  "user_id": "I001",
  "pattern": "A",
  "metacognitive_scores": {
    "p1_task_decomposition": 3,
    "p2_goal_setting": 3,
    ...
  },
  "ml_features": {
    "promptSpecificity": 8.2,
    "verificationRate": 0.82,
    "iterationFrequency": 0.45,
    ...
  },
  "metadata": {
    "interview_date": "2024-05-12",
    "duration_minutes": 67,
    "language": "en",
    "discipline": "CS",
    "expertise": "phd_student"
  }
}
```

---

## ✅ 编码工作流程

### Step 1: 准备阶段
```bash
1. 下载转录文件到 /data/transcripts/
2. 阅读编码手册（本文档）
3. 观看3个示例编码视频
4. 完成练习编码（2份训练转录）
```

### Step 2: 编码阶段
```
For each transcript:
  1. 完整阅读1遍（不做标记）
  2. 第2遍逐段编码：
     - 标记12子过程相关行为
     - 记录证据强度（✓✓✓/✓✓/✓/✗）
     - 复制关键引述
  3. 填写编码表格
  4. 计算总分，初步判定模式
```

### Step 3: 质量检查
```
1. 内部一致性检查
2. 对照已编码案例
3. 不确定案例→团队讨论
4. 每10份转录→计算inter-rater reliability
```

### Step 4: 数据导出
```
1. 生成CSV和JSON
2. 检查缺失值
3. 统计描述（各模式分布）
4. 提交到 /data/training/
```

---

## 📚 参考文献

- Flavell, J. H. (1979). Metacognition and cognitive monitoring: A new area of cognitive–developmental inquiry. *American Psychologist*, 34(10), 906.

- Schraw, G., & Dennison, R. S. (1994). Assessing metacognitive awareness. *Contemporary Educational Psychology*, 19(4), 460-475.

- Azevedo, R., & Hadwin, A. F. (2005). Scaffolding self-regulated learning and metacognition–Implications for the design of computer-based scaffolds. *Instructional Science*, 33(5), 367-379.

- Strauss, A., & Corbin, J. (1998). *Basics of qualitative research: Techniques and procedures for developing grounded theory* (2nd ed.). Sage.

---

**文档版本**：v1.0  
**最后更新**：2024-11  
**编码负责人**：Qi [PhD候选人]  
**审查专家**：3位学习科学家